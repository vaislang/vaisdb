# Context Window Manager
# Expands retrieved chunks to include surrounding context
# Uses chunk graph (NEXT_CHUNK edges) and document hierarchy for expansion
# Respects max_context_tokens limit

U std/vec.Vec;
U std/string.Str;
U std/option.{Option, Some, None};
U storage/error.{VaisError};
U rag/types.{
    ChunkInfo, RagSearchResult, ScoredChunk,
    EDGE_TYPE_NEXT_CHUNK, EDGE_TYPE_SAME_SECTION,
    MAX_HIERARCHY_DEPTH, err_rag_chunk_not_found
};

# ============================================================================
# ContextWindow — Expanded context around a chunk
# ============================================================================

S ContextWindow {
    center_chunk_id: u64,           # The originally retrieved chunk
    chunks_before: Vec<u64>,        # Chunk IDs before center (ordered)
    chunks_after: Vec<u64>,         # Chunk IDs after center (ordered)
    total_tokens: u32,              # Total tokens across all chunks
    expansion_level: u8,            # 0=chunk only, 1=neighbors, 2=section, 3=document
}

X ContextWindow {
    F new(center_chunk_id: u64) -> ContextWindow {
        ContextWindow {
            center_chunk_id,
            chunks_before: Vec.new(),
            chunks_after: Vec.new(),
            total_tokens: 0,
            expansion_level: 0,
        }
    }

    ## Add a chunk before the center
    F add_before(&~self, chunk_id: u64, tokens: u32) {
        self.chunks_before.push(chunk_id);
        self.total_tokens = self.total_tokens + tokens;
    }

    ## Add a chunk after the center
    F add_after(&~self, chunk_id: u64, tokens: u32) {
        self.chunks_after.push(chunk_id);
        self.total_tokens = self.total_tokens + tokens;
    }

    ## Get all chunk IDs in order (before + center + after)
    F all_chunk_ids(self) -> Vec<u64> {
        ~result = Vec.new();

        # Add chunks before (in order)
        ~i: u32 = 0;
        W i < self.chunks_before.len() as u32 {
            result.push(*self.chunks_before.get(i as u64));
            i = i + 1;
        }

        # Add center chunk
        result.push(self.center_chunk_id);

        # Add chunks after (in order)
        ~j: u32 = 0;
        W j < self.chunks_after.len() as u32 {
            result.push(*self.chunks_after.get(j as u64));
            j = j + 1;
        }

        result
    }

    ## Check if adding more would exceed token budget
    F can_expand(self, additional_tokens: u32, max_tokens: u32) -> bool {
        self.total_tokens + additional_tokens <= max_tokens
    }
}

# ============================================================================
# ContextExpander — Builds context windows from chunk graph
# ============================================================================

S ContextExpander {
    max_context_tokens: u32,        # Maximum tokens for expanded context
    max_neighbors: u32,             # Max chunks to include before/after
    expansion_strategy: u8,         # 0=greedy(neighbors first), 1=balanced(equal before/after)
}

X ContextExpander {
    F new(max_tokens: u32) -> ContextExpander {
        ContextExpander {
            max_context_tokens: max_tokens,
            max_neighbors: 3,
            expansion_strategy: 1,
        }
    }

    F default() -> ContextExpander {
        ContextExpander.new(2048)
    }

    ## Expand context for a single chunk using its graph neighbors
    ## next_chunk_edges: pairs of (src, dst) from NEXT_CHUNK edges for this doc
    ## chunk_tokens: map chunk_id -> token_count
    F expand_chunk(
        &self,
        chunk_id: u64,
        chunk_tokens: u32,
        next_chunk_edges: &Vec<(u64, u64)>,
        chunk_token_map: &Vec<(u64, u32)>,
    ) -> ContextWindow {
        ~window = ContextWindow.new(chunk_id);
        window.total_tokens = chunk_tokens;

        # Greedy strategy: expand in one direction until exhausted, then other
        I self.expansion_strategy == 0 {
            # Expand backward
            ~current_id = chunk_id;
            ~before_count: u32 = 0;
            W before_count < self.max_neighbors {
                M find_prev_chunk(current_id, next_chunk_edges) {
                    Some(prev_id) => {
                        ~prev_tokens = get_tokens(prev_id, chunk_token_map);
                        I window.can_expand(prev_tokens, self.max_context_tokens) {
                            window.add_before(prev_id, prev_tokens);
                            current_id = prev_id;
                            before_count = before_count + 1;
                        } E {
                            before_count = self.max_neighbors; # Stop
                        }
                    },
                    None => {
                        before_count = self.max_neighbors; # Stop
                    },
                }
            }

            # Expand forward
            ~current_fwd = chunk_id;
            ~after_count: u32 = 0;
            W after_count < self.max_neighbors {
                M find_next_chunk(current_fwd, next_chunk_edges) {
                    Some(next_id) => {
                        ~next_tokens = get_tokens(next_id, chunk_token_map);
                        I window.can_expand(next_tokens, self.max_context_tokens) {
                            window.add_after(next_id, next_tokens);
                            current_fwd = next_id;
                            after_count = after_count + 1;
                        } E {
                            after_count = self.max_neighbors; # Stop
                        }
                    },
                    None => {
                        after_count = self.max_neighbors; # Stop
                    },
                }
            }
        } E {
            # Balanced strategy: alternate before/after
            ~current_before = chunk_id;
            ~current_after = chunk_id;
            ~before_count: u32 = 0;
            ~after_count: u32 = 0;
            ~total_added = before_count + after_count;

            W total_added < self.max_neighbors * 2 {
                # Try adding before
                I before_count < self.max_neighbors {
                    M find_prev_chunk(current_before, next_chunk_edges) {
                        Some(prev_id) => {
                            ~prev_tokens = get_tokens(prev_id, chunk_token_map);
                            I window.can_expand(prev_tokens, self.max_context_tokens) {
                                window.add_before(prev_id, prev_tokens);
                                current_before = prev_id;
                                before_count = before_count + 1;
                                total_added = total_added + 1;
                            } E {
                                before_count = self.max_neighbors; # Stop before
                            }
                        },
                        None => {
                            before_count = self.max_neighbors; # Stop before
                        },
                    }
                }

                # Try adding after
                I after_count < self.max_neighbors {
                    M find_next_chunk(current_after, next_chunk_edges) {
                        Some(next_id) => {
                            ~next_tokens = get_tokens(next_id, chunk_token_map);
                            I window.can_expand(next_tokens, self.max_context_tokens) {
                                window.add_after(next_id, next_tokens);
                                current_after = next_id;
                                after_count = after_count + 1;
                                total_added = total_added + 1;
                            } E {
                                after_count = self.max_neighbors; # Stop after
                            }
                        },
                        None => {
                            after_count = self.max_neighbors; # Stop after
                        },
                    }
                }

                # Exit if both directions exhausted
                I before_count >= self.max_neighbors && after_count >= self.max_neighbors {
                    total_added = self.max_neighbors * 2; # Exit loop
                }
            }
        }

        window.expansion_level = 1;
        window
    }

    ## Expand context for multiple chunks (batch), deduplicating overlapping windows
    F expand_batch(
        &self,
        chunk_ids: &Vec<u64>,
        chunk_token_counts: &Vec<u32>,
        next_chunk_edges: &Vec<(u64, u64)>,
        chunk_token_map: &Vec<(u64, u32)>,
    ) -> Vec<ContextWindow> {
        ~windows = Vec.new();

        # Expand each chunk
        ~i: u32 = 0;
        W i < chunk_ids.len() as u32 {
            ~chunk_id = *chunk_ids.get(i as u64);
            ~tokens = *chunk_token_counts.get(i as u64);
            ~window = self.expand_chunk(chunk_id, tokens, next_chunk_edges, chunk_token_map);
            windows.push(window);
            i = i + 1;
        }

        # Merge overlapping windows
        ContextExpander.merge_overlapping(&windows)
    }

    ## Merge overlapping context windows
    F merge_overlapping(windows: &Vec<ContextWindow>) -> Vec<ContextWindow> {
        I windows.len() == 0 {
            R Vec.new();
        }

        ~merged = Vec.new();
        ~used = Vec.new();

        # Initialize used flags
        ~k: u32 = 0;
        W k < windows.len() as u32 {
            used.push(false);
            k = k + 1;
        }

        # Process each window
        ~i: u32 = 0;
        W i < windows.len() as u32 {
            I *used.get(i as u64) {
                i = i + 1;
                C;
            }

            ~window_a = windows.get(i as u64);
            ~chunks_a = window_a.all_chunk_ids();
            ~merged_window = ContextWindow.new(window_a.center_chunk_id);
            merged_window.chunks_before = window_a.chunks_before.clone();
            merged_window.chunks_after = window_a.chunks_after.clone();
            merged_window.total_tokens = window_a.total_tokens;
            merged_window.expansion_level = window_a.expansion_level;

            # Check for overlaps with other windows
            ~j: u32 = i + 1;
            W j < windows.len() as u32 {
                I *used.get(j as u64) {
                    j = j + 1;
                    C;
                }

                ~window_b = windows.get(j as u64);
                ~chunks_b = window_b.all_chunk_ids();

                # Check if windows overlap
                ~overlaps = false;
                ~m: u32 = 0;
                W m < chunks_a.len() as u32 && !overlaps {
                    ~chunk_a = *chunks_a.get(m as u64);
                    ~n: u32 = 0;
                    W n < chunks_b.len() as u32 {
                        I chunk_a == *chunks_b.get(n as u64) {
                            overlaps = true;
                        }
                        n = n + 1;
                    }
                    m = m + 1;
                }

                I overlaps {
                    # Mark as used
                    *used.get_mut(j as u64) = true;
                }

                j = j + 1;
            }

            *used.get_mut(i as u64) = true;
            merged.push(merged_window);
            i = i + 1;
        }

        merged
    }
}

# Helper: find previous chunk in NEXT_CHUNK edges
F find_prev_chunk(chunk_id: u64, edges: &Vec<(u64, u64)>) -> Option<u64> {
    ~i: u32 = 0;
    W i < edges.len() as u32 {
        ~edge = edges.get(i as u64);
        I edge.1 == chunk_id {
            R Some(edge.0);
        }
        i = i + 1;
    }
    None
}

# Helper: find next chunk in NEXT_CHUNK edges
F find_next_chunk(chunk_id: u64, edges: &Vec<(u64, u64)>) -> Option<u64> {
    ~i: u32 = 0;
    W i < edges.len() as u32 {
        ~edge = edges.get(i as u64);
        I edge.0 == chunk_id {
            R Some(edge.1);
        }
        i = i + 1;
    }
    None
}

# Helper: get token count from map
F get_tokens(chunk_id: u64, token_map: &Vec<(u64, u32)>) -> u32 {
    ~i: u32 = 0;
    W i < token_map.len() as u32 {
        ~entry = token_map.get(i as u64);
        I entry.0 == chunk_id {
            R entry.1;
        }
        i = i + 1;
    }
    0
}
