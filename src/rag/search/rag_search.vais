# RAG_SEARCH() SQL Function Executor
# SQL interface: RAG_SEARCH(query_text, top_k, fusion_method, vector_weight,
#                           fulltext_weight, graph_weight, max_context_tokens)
# Volcano-style iterator: open → next → close
# Orchestrates vector search, full-text search, graph traversal, and score fusion
# Returns RagSearchResult rows for SQL query execution

U std/vec.Vec;
U std/string.Str;
U std/option.{Option, Some, None};
U storage/error.{VaisError};
U rag/types.{
    RagSearchResult, RagFusionConfig, ScoredChunk, ChunkInfo,
    ENGINE_TAG_RAG, DEFAULT_VECTOR_WEIGHT, DEFAULT_FULLTEXT_WEIGHT,
    DEFAULT_GRAPH_WEIGHT, DEFAULT_MEMORY_WEIGHT,
    err_rag_engine_closed, err_rag_chunk_not_found
};

# ============================================================================
# Error Codes: EE=08 (RAG), CC=09 (search)
# ============================================================================

F err_rag_search_failed(reason: &Str) -> VaisError {
    VaisError.new(
        "VAIS-0809001",
        "RAG_SEARCH failed: {reason}"
    )
}

F err_rag_search_not_open() -> VaisError {
    VaisError.new(
        "VAIS-0809002",
        "RAG_SEARCH executor not opened"
    )
}

F err_rag_search_invalid_params(reason: &Str) -> VaisError {
    VaisError.new(
        "VAIS-0809003",
        "Invalid RAG_SEARCH parameters: {reason}"
    )
}

# ============================================================================
# RagSearchParams — Parameters parsed from RAG_SEARCH() function call
# ============================================================================

S RagSearchParams {
    query_text: Str,                # User query string
    top_k: u32,                     # Number of results to return
    fusion_method: u8,              # 0=WeightedSum, 1=RRF
    vector_weight: f64,
    fulltext_weight: f64,
    graph_weight: f64,
    memory_weight: f64,
    rrf_k: u32,                     # RRF constant (default 60)
    max_context_tokens: u32,        # Max tokens for context expansion
    include_context: bool,          # Whether to expand context window
    filter_doc_ids: Vec<u64>,       # Optional: restrict to specific documents
}

X RagSearchParams {
    ## Create with default weights
    F default(query_text: Str, top_k: u32) -> RagSearchParams {
        RagSearchParams {
            query_text,
            top_k,
            fusion_method: 0,
            vector_weight: DEFAULT_VECTOR_WEIGHT,
            fulltext_weight: DEFAULT_FULLTEXT_WEIGHT,
            graph_weight: DEFAULT_GRAPH_WEIGHT,
            memory_weight: DEFAULT_MEMORY_WEIGHT,
            rrf_k: 60,
            max_context_tokens: 2048,
            include_context: true,
            filter_doc_ids: Vec.new(),
        }
    }

    ## Create from explicit fusion config
    F from_config(query_text: Str, config: &RagFusionConfig) -> RagSearchParams {
        RagSearchParams {
            query_text,
            top_k: config.top_k,
            fusion_method: config.fusion_method,
            vector_weight: config.vector_weight,
            fulltext_weight: config.fulltext_weight,
            graph_weight: config.graph_weight,
            memory_weight: config.memory_weight,
            rrf_k: config.rrf_k,
            max_context_tokens: config.max_context_tokens,
            include_context: true,
            filter_doc_ids: Vec.new(),
        }
    }

    ## Validate parameters
    F validate(&self) -> Result<(), VaisError> {
        if self.query_text.is_empty() {
            return Err(err_rag_search_invalid_params(&"query_text is empty"));
        }
        if self.top_k == 0 {
            return Err(err_rag_search_invalid_params(&"top_k must be > 0"));
        }
        ~total_weight = self.vector_weight + self.fulltext_weight + self.graph_weight;
        if total_weight < 0.01 {
            return Err(err_rag_search_invalid_params(&"All search weights are zero"));
        }
        Ok(())
    }
}

# ============================================================================
# EngineResultSet — Results from a single engine search
# ============================================================================

S EngineResultSet {
    engine_tag: u8,                 # Which engine produced these results
    scored_chunks: Vec<ScoredChunk>,
}

X EngineResultSet {
    F new(engine_tag: u8) -> EngineResultSet {
        EngineResultSet {
            engine_tag,
            scored_chunks: Vec.new(),
        }
    }

    ## Add a scored chunk result
    F add(~self, chunk_id: u64, doc_id: u64, score: f64) {
        self.scored_chunks.push(ScoredChunk.new(chunk_id, doc_id, score, self.engine_tag));
    }

    ## Get result count
    F len(&self) -> u32 {
        self.scored_chunks.len() as u32
    }

    ## Check if empty
    F is_empty(&self) -> bool {
        self.scored_chunks.len() == 0
    }
}

# ============================================================================
# RagSearchExecutor — Volcano-style executor for RAG_SEARCH()
# ============================================================================

S RagSearchExecutor {
    params: RagSearchParams,
    results: Vec<RagSearchResult>,
    cursor: u32,
    is_open: bool,
    exec_time_us: u64,              # Execution time in microseconds
}

X RagSearchExecutor {
    ## Create a new RAG search executor
    F new(params: RagSearchParams) -> RagSearchExecutor {
        RagSearchExecutor {
            params,
            results: Vec.new(),
            cursor: 0,
            is_open: false,
            exec_time_us: 0,
        }
    }

    ## Open the executor — triggers the full search pipeline
    ## This materializes all results since score fusion requires global normalization
    ##
    ## Pipeline:
    ## 1. Vector search (HNSW) → ScoredChunks
    ## 2. Full-text search (BM25) → ScoredChunks
    ## 3. Graph proximity boost → ScoredChunks
    ## 4. Normalize + fuse scores
    ## 5. Sort by fused score, take top_k
    ## 6. Expand context windows (optional)
    ## 7. Build RagSearchResult records
    F open(~self,
           vector_results: &EngineResultSet,
           fulltext_results: &EngineResultSet,
           graph_boost_results: &EngineResultSet,
           chunk_text_lookup: &Vec<(u64, Str)>,
    ) -> Result<(), VaisError> {
        self.params.validate()?;

        # Step 1-3: Engine results are passed in by the caller (RagSearchPipeline)
        # We just need to fuse them here

        # Step 4: Normalize and fuse
        ~fused = M self.params.fusion_method {
            0 => fuse_weighted_sum(
                vector_results, fulltext_results, graph_boost_results,
                self.params.vector_weight, self.params.fulltext_weight,
                self.params.graph_weight,
            ),
            1 => fuse_rrf(
                vector_results, fulltext_results, graph_boost_results,
                self.params.rrf_k,
            ),
            _ => fuse_weighted_sum(
                vector_results, fulltext_results, graph_boost_results,
                self.params.vector_weight, self.params.fulltext_weight,
                self.params.graph_weight,
            ),
        };

        # Step 5: Sort by score descending, take top_k
        sort_scored_chunks_desc(&~fused);

        ~limit = if self.params.top_k < fused.len() as u32 {
            self.params.top_k
        } else {
            fused.len() as u32
        };

        # Step 6-7: Build RagSearchResult from top_k fused chunks
        ~i: u32 = 0;
        W i < limit {
            ~sc = fused.get(i as usize);

            # Look up chunk text
            ~text = lookup_chunk_text(sc.chunk_id, chunk_text_lookup);

            ~result = RagSearchResult.new(
                sc.doc_id, sc.chunk_id, sc.score, text
            );
            result = result.with_parent(sc.doc_id);

            self.results.push(result);
            i = i + 1;
        }

        self.cursor = 0;
        self.is_open = true;
        Ok(())
    }

    ## Get the next result (Volcano iterator)
    F next(&~self) -> Option<&RagSearchResult> {
        if !self.is_open {
            return None;
        }
        if self.cursor >= self.results.len() as u32 {
            return None;
        }
        ~result = self.results.get(self.cursor as usize);
        self.cursor = self.cursor + 1;
        Some(result)
    }

    ## Close the executor
    F close(~self) {
        self.is_open = false;
        self.results = Vec.new();
        self.cursor = 0;
    }

    ## Get total result count
    F result_count(&self) -> u32 {
        self.results.len() as u32
    }

    ## Get all results (for non-iterator access)
    F get_results(&self) -> &Vec<RagSearchResult> {
        &self.results
    }

    ## Get execution time
    F exec_time(&self) -> u64 {
        self.exec_time_us
    }

    ## Set execution time (called by pipeline after measurement)
    F set_exec_time(~self, us: u64) {
        self.exec_time_us = us;
    }
}

# ============================================================================
# Score Fusion — Multi-engine score normalization and combination
# ============================================================================

## Weighted sum fusion across 3 engine result sets
## 1. Normalize each set to [0, 1] via min-max
## 2. For each unique chunk_id: fused = w_v*v + w_f*f + w_g*g
## 3. Return combined results (unsorted)
F fuse_weighted_sum(
    vector_results: &EngineResultSet,
    fulltext_results: &EngineResultSet,
    graph_results: &EngineResultSet,
    weight_v: f64,
    weight_f: f64,
    weight_g: f64,
) -> Vec<ScoredChunk> {
    ~norm_v = normalize_engine_scores(&vector_results.scored_chunks);
    ~norm_f = normalize_engine_scores(&fulltext_results.scored_chunks);
    ~norm_g = normalize_engine_scores(&graph_results.scored_chunks);

    # Collect all unique chunk_ids
    ~all_chunks: Vec<(u64, u64)> = Vec.new();  # (chunk_id, doc_id)
    collect_unique_chunks(&norm_v, &~all_chunks);
    collect_unique_chunks(&norm_f, &~all_chunks);
    collect_unique_chunks(&norm_g, &~all_chunks);

    # For each unique chunk, compute fused score
    ~result = Vec.new();
    ~i: u32 = 0;
    W i < all_chunks.len() as u32 {
        ~chunk_id = all_chunks.get(i as usize).0;
        ~doc_id = all_chunks.get(i as usize).1;

        ~score_v = find_chunk_score(chunk_id, &norm_v);
        ~score_f = find_chunk_score(chunk_id, &norm_f);
        ~score_g = find_chunk_score(chunk_id, &norm_g);

        ~fused = weight_v * score_v + weight_f * score_f + weight_g * score_g;
        result.push(ScoredChunk.new(chunk_id, doc_id, fused, ENGINE_TAG_RAG));
        i = i + 1;
    }
    result
}

## Reciprocal Rank Fusion across 3 engine result sets
## Score = Σ 1/(k + rank_i) across all lists where chunk appears
F fuse_rrf(
    vector_results: &EngineResultSet,
    fulltext_results: &EngineResultSet,
    graph_results: &EngineResultSet,
    k: u32,
) -> Vec<ScoredChunk> {
    ~k_f64 = k as f64;

    # Collect all unique chunk_ids
    ~all_chunks: Vec<(u64, u64)> = Vec.new();  # (chunk_id, doc_id)
    collect_unique_chunks(&vector_results.scored_chunks, &~all_chunks);
    collect_unique_chunks(&fulltext_results.scored_chunks, &~all_chunks);
    collect_unique_chunks(&graph_results.scored_chunks, &~all_chunks);

    # For each unique chunk, compute RRF score
    ~result = Vec.new();
    ~i: u32 = 0;
    W i < all_chunks.len() as u32 {
        ~chunk_id = all_chunks.get(i as usize).0;
        ~doc_id = all_chunks.get(i as usize).1;

        ~rrf_score: f64 = 0.0;

        # Check rank in vector results
        ~rank_v = find_rank(chunk_id, &vector_results.scored_chunks);
        if rank_v > 0 {
            rrf_score = rrf_score + 1.0 / (k_f64 + rank_v as f64);
        }

        # Check rank in fulltext results
        ~rank_f = find_rank(chunk_id, &fulltext_results.scored_chunks);
        if rank_f > 0 {
            rrf_score = rrf_score + 1.0 / (k_f64 + rank_f as f64);
        }

        # Check rank in graph results
        ~rank_g = find_rank(chunk_id, &graph_results.scored_chunks);
        if rank_g > 0 {
            rrf_score = rrf_score + 1.0 / (k_f64 + rank_g as f64);
        }

        result.push(ScoredChunk.new(chunk_id, doc_id, rrf_score, ENGINE_TAG_RAG));
        i = i + 1;
    }
    result
}

# ============================================================================
# Helpers
# ============================================================================

## Normalize scores to [0, 1] via min-max normalization
F normalize_engine_scores(chunks: &Vec<ScoredChunk>) -> Vec<ScoredChunk> {
    if chunks.len() == 0 {
        return Vec.new();
    }

    # Find min and max
    ~min_s = chunks.get(0).score;
    ~max_s = chunks.get(0).score;
    ~i: u32 = 1;
    W i < chunks.len() as u32 {
        ~s = chunks.get(i as usize).score;
        if s < min_s { min_s = s; }
        if s > max_s { max_s = s; }
        i = i + 1;
    }

    ~range = max_s - min_s;
    ~result = Vec.new();

    if range < 0.000001 {
        # All scores equal → normalize to 1.0
        ~j: u32 = 0;
        W j < chunks.len() as u32 {
            ~c = chunks.get(j as usize);
            result.push(ScoredChunk.new(c.chunk_id, c.doc_id, 1.0, c.source_engine));
            j = j + 1;
        }
    } else {
        ~j: u32 = 0;
        W j < chunks.len() as u32 {
            ~c = chunks.get(j as usize);
            ~norm = (c.score - min_s) / range;
            result.push(ScoredChunk.new(c.chunk_id, c.doc_id, norm, c.source_engine));
            j = j + 1;
        }
    }
    result
}

## Collect unique (chunk_id, doc_id) pairs into accumulator
F collect_unique_chunks(chunks: &Vec<ScoredChunk>, acc: &~Vec<(u64, u64)>) {
    ~i: u32 = 0;
    W i < chunks.len() as u32 {
        ~c = chunks.get(i as usize);
        ~already_present = false;
        ~j: u32 = 0;
        W j < acc.len() as u32 {
            if acc.get(j as usize).0 == c.chunk_id {
                already_present = true;
                j = acc.len() as u32;  # Break
            }
            j = j + 1;
        }
        if !already_present {
            acc.push((c.chunk_id, c.doc_id));
        }
        i = i + 1;
    }
}

## Find a chunk's normalized score in a result set (0.0 if not present)
F find_chunk_score(chunk_id: u64, chunks: &Vec<ScoredChunk>) -> f64 {
    ~i: u32 = 0;
    W i < chunks.len() as u32 {
        ~c = chunks.get(i as usize);
        if c.chunk_id == chunk_id {
            return c.score;
        }
        i = i + 1;
    }
    0.0
}

## Find 1-based rank of a chunk in a result set (0 if not present)
## Assumes results are pre-sorted by score descending by the engine
F find_rank(chunk_id: u64, chunks: &Vec<ScoredChunk>) -> u32 {
    ~i: u32 = 0;
    W i < chunks.len() as u32 {
        if chunks.get(i as usize).chunk_id == chunk_id {
            return i + 1;  # 1-based rank
        }
        i = i + 1;
    }
    0
}

## Sort scored chunks by score descending (selection sort — small N expected)
F sort_scored_chunks_desc(chunks: &~Vec<ScoredChunk>) {
    ~n = chunks.len() as u32;
    ~i: u32 = 0;
    W i < n {
        ~max_idx = i;
        ~j = i + 1;
        W j < n {
            if chunks.get(j as usize).score > chunks.get(max_idx as usize).score {
                max_idx = j;
            }
            j = j + 1;
        }
        if max_idx != i {
            chunks.swap(i as usize, max_idx as usize);
        }
        i = i + 1;
    }
}

## Look up chunk text from a (chunk_id, text) lookup table
F lookup_chunk_text(chunk_id: u64, lookup: &Vec<(u64, Str)>) -> Str {
    ~i: u32 = 0;
    W i < lookup.len() as u32 {
        ~entry = lookup.get(i as usize);
        if entry.0 == chunk_id {
            return entry.1.clone();
        }
        i = i + 1;
    }
    Str.new()
}
