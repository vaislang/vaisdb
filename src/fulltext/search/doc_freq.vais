# Document Frequency Tracker
# Tracks document frequency (DF) and total term frequency for BM25 scoring
# In-memory cache synchronized with on-disk dictionary

U std/vec.Vec;
U fulltext/types.{DictEntry};

# ============================================================================
# DocFreqEntry — In-memory document frequency tracking entry
# ============================================================================

S DocFreqEntry {
    term_hash: u64,         # FNV-1a hash of the term
    doc_freq: u32,          # Number of documents containing this term
    total_term_freq: u64,   # Total occurrences across all documents
}

X DocFreqEntry {
    F new(term_hash: u64) -> DocFreqEntry {
        DocFreqEntry {
            term_hash,
            doc_freq: 0,
            total_term_freq: 0,
        }
    }

    F with_stats(term_hash: u64, doc_freq: u32, total_term_freq: u64) -> DocFreqEntry {
        DocFreqEntry {
            term_hash,
            doc_freq,
            total_term_freq,
        }
    }
}

# ============================================================================
# DocFreqTracker — Document frequency tracking for BM25 scoring
# ============================================================================

S DocFreqTracker {
    entries: Vec<DocFreqEntry>,  # Vec of (term_hash, doc_freq, total_term_freq)
    total_docs: u64,             # Total number of documents indexed
    avg_doc_length: f64,         # Average document length in tokens
}

X DocFreqTracker {
    # Create new empty document frequency tracker
    F new() -> DocFreqTracker {
        DocFreqTracker {
            entries: Vec.new(),
            total_docs: 0,
            avg_doc_length: 0.0,
        }
    }

    # Update document frequency when inserting a new document
    # Increments DF by 1 and adds term_freq to total_term_freq
    #
    # Parameters:
    # - term_hash: FNV-1a hash of the term
    # - term_freq: frequency of this term in the new document
    F update_on_insert(~self, term_hash: u64, term_freq: u32) {
        # Find existing entry
        ~found_idx = self.find_entry_index(term_hash);

        M found_idx {
            Some(idx) -> {
                # Update existing entry
                self.entries[idx].doc_freq += 1;
                self.entries[idx].total_term_freq += term_freq as u64;
            }
            None -> {
                # Create new entry
                ~entry = DocFreqEntry.with_stats(term_hash, 1, term_freq as u64);
                self.entries.push(entry);
            }
        }
    }

    # Update document frequency when deleting a document
    # Decrements DF by 1 and subtracts term_freq from total_term_freq
    #
    # Parameters:
    # - term_hash: FNV-1a hash of the term
    # - term_freq: frequency of this term in the deleted document
    F update_on_delete(~self, term_hash: u64, term_freq: u32) {
        ~found_idx = self.find_entry_index(term_hash);

        M found_idx {
            Some(idx) -> {
                # Decrement counters
                I self.entries[idx].doc_freq > 0 {
                    self.entries[idx].doc_freq -= 1;
                }
                I self.entries[idx].total_term_freq >= term_freq as u64 {
                    self.entries[idx].total_term_freq -= term_freq as u64;
                } E {
                    self.entries[idx].total_term_freq = 0;
                }

                # Remove entry if no longer present in any document
                I self.entries[idx].doc_freq == 0 {
                    self.entries.remove(idx);
                }
            }
            None -> {
                # Term not tracked (should not happen in normal operation)
            }
        }
    }

    # Get document frequency for a term
    # Returns 0 if term not found
    F get_df(self, term_hash: u64) -> u32 {
        ~found_idx = self.find_entry_index(term_hash);
        M found_idx {
            Some(idx) -> self.entries[idx].doc_freq,
            None -> 0,
        }
    }

    # Get total term frequency across all documents
    # Returns 0 if term not found
    F get_total_term_freq(self, term_hash: u64) -> u64 {
        ~found_idx = self.find_entry_index(term_hash);
        M found_idx {
            Some(idx) -> self.entries[idx].total_term_freq,
            None -> 0,
        }
    }

    # Get total number of documents in corpus
    F get_total_docs(self) -> u64 {
        self.total_docs
    }

    # Get average document length in tokens
    F get_avg_doc_length(self) -> f64 {
        self.avg_doc_length
    }

    # Set total document count
    # Called by full-text engine when documents are added/removed
    F set_total_docs(~self, count: u64) {
        self.total_docs = count;
    }

    # Set average document length
    # Called by full-text engine when corpus statistics change
    F set_avg_doc_length(~self, avg: f64) {
        self.avg_doc_length = avg;
    }

    # Recalibrate from dictionary entries
    # Rebuilds in-memory tracker from on-disk dictionary state
    # Used during engine initialization or after crash recovery
    #
    # Parameters:
    # - entries: Vec of DictEntry from the dictionary
    F recalibrate_from_dict(~self, entries: &Vec<DictEntry>) {
        # Clear existing entries
        self.entries.clear();

        # Rebuild from dictionary
        ~i: u64 = 0;
        L W i < entries.len() {
            ~dict_entry = &entries[i];
            ~freq_entry = DocFreqEntry.with_stats(
                dict_entry.term_hash,
                dict_entry.doc_freq,
                dict_entry.total_term_freq,
            );
            self.entries.push(freq_entry);
            i += 1;
        }
    }

    # Find entry index by term hash (linear search)
    # Returns Some(index) if found, None otherwise
    #
    # Note: For production use, this should be replaced with a HashMap (std/hashmap.vais)
    F find_entry_index(self, term_hash: u64) -> Option<u64> {
        ~i: u64 = 0;
        L W i < self.entries.len() {
            I self.entries[i].term_hash == term_hash {
                R Some(i);
            }
            i += 1;
        }
        None
    }

    # Get all tracked term hashes
    # Useful for debugging and statistics
    F get_tracked_terms(self) -> Vec<u64> {
        ~result = Vec.with_capacity(self.entries.len());
        ~i: u64 = 0;
        L W i < self.entries.len() {
            result.push(self.entries[i].term_hash);
            i += 1;
        }
        result
    }

    # Get number of tracked terms
    F get_term_count(self) -> u64 {
        self.entries.len()
    }

    # Clear all tracking data
    # Used when rebuilding index or during testing
    F clear(~self) {
        self.entries.clear();
        self.total_docs = 0;
        self.avg_doc_length = 0.0;
    }
}

# ============================================================================
# Unit tests
# ============================================================================

#[test]
F test_docfreq_tracker_new() {
    ~tracker = DocFreqTracker.new();
    assert_eq!(tracker.get_total_docs(), 0);
    assert_eq!(tracker.get_avg_doc_length(), 0.0);
    assert_eq!(tracker.get_term_count(), 0);
}

#[test]
F test_update_on_insert() {
    ~tracker = DocFreqTracker.new();

    # Insert term "hello" (hash=12345) with tf=3
    tracker.update_on_insert(12345, 3);

    assert_eq!(tracker.get_df(12345), 1);
    assert_eq!(tracker.get_total_term_freq(12345), 3);

    # Insert same term in another document with tf=2
    tracker.update_on_insert(12345, 2);

    assert_eq!(tracker.get_df(12345), 2);
    assert_eq!(tracker.get_total_term_freq(12345), 5);
}

#[test]
F test_update_on_delete() {
    ~tracker = DocFreqTracker.new();

    # Insert term twice
    tracker.update_on_insert(12345, 3);
    tracker.update_on_insert(12345, 2);

    # Delete one document
    tracker.update_on_delete(12345, 2);

    assert_eq!(tracker.get_df(12345), 1);
    assert_eq!(tracker.get_total_term_freq(12345), 3);

    # Delete last document
    tracker.update_on_delete(12345, 3);

    # Term should be removed
    assert_eq!(tracker.get_df(12345), 0);
    assert_eq!(tracker.get_term_count(), 0);
}

#[test]
F test_update_on_delete_edge_cases() {
    ~tracker = DocFreqTracker.new();

    # Delete non-existent term (should not crash)
    tracker.update_on_delete(99999, 1);

    # Insert and delete more than inserted
    tracker.update_on_insert(12345, 5);
    tracker.update_on_delete(12345, 10);  # More than inserted

    # Should clamp to 0
    assert_eq!(tracker.get_total_term_freq(12345), 0);
}

#[test]
F test_get_df_not_found() {
    ~tracker = DocFreqTracker.new();
    assert_eq!(tracker.get_df(99999), 0);
    assert_eq!(tracker.get_total_term_freq(99999), 0);
}

#[test]
F test_set_total_docs_and_avg_length() {
    ~tracker = DocFreqTracker.new();

    tracker.set_total_docs(1000);
    tracker.set_avg_doc_length(120.5);

    assert_eq!(tracker.get_total_docs(), 1000);
    assert_eq!(tracker.get_avg_doc_length(), 120.5);
}

#[test]
F test_recalibrate_from_dict() {
    ~tracker = DocFreqTracker.new();

    # Create dictionary entries
    ~dict_entries = Vec.new();

    ~entry1 = DictEntry.new(Str.from("hello"), 12345, 100);
    entry1.doc_freq = 10;
    entry1.total_term_freq = 42;
    dict_entries.push(entry1);

    ~entry2 = DictEntry.new(Str.from("world"), 67890, 200);
    entry2.doc_freq = 8;
    entry2.total_term_freq = 25;
    dict_entries.push(entry2);

    # Recalibrate
    tracker.recalibrate_from_dict(&dict_entries);

    # Verify entries
    assert_eq!(tracker.get_term_count(), 2);
    assert_eq!(tracker.get_df(12345), 10);
    assert_eq!(tracker.get_total_term_freq(12345), 42);
    assert_eq!(tracker.get_df(67890), 8);
    assert_eq!(tracker.get_total_term_freq(67890), 25);
}

#[test]
F test_get_tracked_terms() {
    ~tracker = DocFreqTracker.new();

    tracker.update_on_insert(12345, 1);
    tracker.update_on_insert(67890, 2);
    tracker.update_on_insert(11111, 3);

    ~terms = tracker.get_tracked_terms();
    assert_eq!(terms.len(), 3);

    # Verify all terms are present (order may vary)
    ~found_12345 = false;
    ~found_67890 = false;
    ~found_11111 = false;

    ~i: u64 = 0;
    L W i < terms.len() {
        I terms[i] == 12345 { found_12345 = true; }
        I terms[i] == 67890 { found_67890 = true; }
        I terms[i] == 11111 { found_11111 = true; }
        i += 1;
    }

    assert!(found_12345);
    assert!(found_67890);
    assert!(found_11111);
}

#[test]
F test_clear() {
    ~tracker = DocFreqTracker.new();

    tracker.update_on_insert(12345, 5);
    tracker.update_on_insert(67890, 3);
    tracker.set_total_docs(100);
    tracker.set_avg_doc_length(50.0);

    tracker.clear();

    assert_eq!(tracker.get_term_count(), 0);
    assert_eq!(tracker.get_total_docs(), 0);
    assert_eq!(tracker.get_avg_doc_length(), 0.0);
}

#[test]
F test_multiple_terms_tracking() {
    ~tracker = DocFreqTracker.new();

    # Simulate indexing documents with multiple terms
    # Doc 1: "hello world hello"
    tracker.update_on_insert(12345, 2);  # hello: tf=2
    tracker.update_on_insert(67890, 1);  # world: tf=1

    # Doc 2: "hello vais"
    tracker.update_on_insert(12345, 1);  # hello: tf=1
    tracker.update_on_insert(11111, 1);  # vais: tf=1

    # Doc 3: "world vais vais"
    tracker.update_on_insert(67890, 1);  # world: tf=1
    tracker.update_on_insert(11111, 2);  # vais: tf=2

    # Verify final state
    assert_eq!(tracker.get_df(12345), 2);  # hello in 2 docs
    assert_eq!(tracker.get_total_term_freq(12345), 3);  # 2+1=3 occurrences

    assert_eq!(tracker.get_df(67890), 2);  # world in 2 docs
    assert_eq!(tracker.get_total_term_freq(67890), 2);  # 1+1=2 occurrences

    assert_eq!(tracker.get_df(11111), 2);  # vais in 2 docs
    assert_eq!(tracker.get_total_term_freq(11111), 3);  # 1+2=3 occurrences
}
