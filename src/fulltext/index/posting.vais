# Full-Text Posting List Storage
# Manages posting list pages with page chaining for large posting lists
# Slotted page layout: PostingPageHeader + slot directory + PostingEntry data
# WAL-first operations: all mutations logged before applied

U std/vec.Vec;
U std/bytes.{ByteBuffer};
U std/option.{Option, Some, None};
U storage/constants.{
    PAGE_HEADER_SIZE, NULL_PAGE, FILE_ID_FULLTEXT,
    INVALID_TXN_ID, SLOT_ENTRY_SIZE
};
U storage/error.{VaisError};
U storage/page/header.{PageHeader};
U storage/page/types.{PAGE_TYPE_INVERTED_POSTING, ENGINE_TAG_FULLTEXT};
U storage/buffer/pool.{BufferPool};
U storage/page/allocator.{PageAllocator};
U storage/wal/group_commit.{GroupCommitManager};
U fulltext/types.{
    PostingEntry, PostingPageHeader, POSTING_PAGE_HEADER_SIZE,
    err_fulltext_posting_corrupt, err_fulltext_page_full
};

# ============================================================================
# PostingSlot — Slot directory entry (4 bytes) pointing to PostingEntry
# ============================================================================

S PostingSlot {
    offset: u16,     # Byte offset within page body (after headers)
    length: u16,     # Length of serialized PostingEntry
}

X PostingSlot {
    F serialize(self, buf: &~ByteBuffer) {
        buf.put_u16_le(self.offset);
        buf.put_u16_le(self.length);
    }

    F deserialize(buf: &ByteBuffer) -> Result<PostingSlot, VaisError> {
        Ok(PostingSlot {
            offset: buf.get_u16_le()?,
            length: buf.get_u16_le()?,
        })
    }
}

# ============================================================================
# PostingStore — Manages posting list pages
# ============================================================================

S PostingStore {
    page_size: u32,
    pool: &BufferPool,
    allocator: &PageAllocator,
}

X PostingStore {
    F new(
        page_size: u32,
        pool: &BufferPool,
        allocator: &PageAllocator,
    ) -> PostingStore {
        PostingStore { page_size, pool, allocator }
    }

    # ========================================================================
    # Append a PostingEntry to a posting list
    # Returns (page_id, slot_index) where entry was stored
    # If the current head page is full, allocates a new page and chains it
    # ========================================================================

    F append_entry(
        ~self,
        head_page_id: u32,
        entry: &PostingEntry,
        term_hash: u64,
        txn_id: u64,
        gcm: &~GroupCommitManager,
    ) -> Result<(u32, u16, u32), VaisError> {
        # Serialize entry to determine size
        ~entry_buf = ByteBuffer.new(entry.serialized_size() as usize);
        entry.serialize(&entry_buf);
        ~entry_bytes = entry_buf.to_vec();
        ~entry_size = entry_bytes.len() as u32;

        # Try to find a page with enough space
        ~current_page_id = head_page_id;
        ~new_head = head_page_id;

        if current_page_id == NULL_PAGE {
            # No posting list exists yet — allocate first page
            ~new_page_id = self.allocator.allocate_page(FILE_ID_FULLTEXT)?;
            self.init_posting_page(new_page_id, term_hash, gcm)?;
            current_page_id = new_page_id;
            new_head = new_page_id;
        }

        # Walk the page chain to find space
        L {
            ~page_data = self.pool.get_page(current_page_id, FILE_ID_FULLTEXT)?;
            ~buf = ByteBuffer.wrap_readonly(&page_data);

            # Skip page header
            buf.set_position(PAGE_HEADER_SIZE as usize);

            # Read posting page header
            ~pph = PostingPageHeader.deserialize(&buf)?;

            # Calculate used space
            ~used = Self.calculate_used_space(&pph, self.page_size, &page_data);
            ~available = self.page_size - PAGE_HEADER_SIZE - POSTING_PAGE_HEADER_SIZE - used;

            # Need space for: slot entry (4B) + entry data
            ~needed = SLOT_ENTRY_SIZE + entry_size;

            if available >= needed {
                # Enough space — write entry to this page
                ~slot_index = pph.entry_count;
                self.write_entry_to_page(current_page_id, &pph, &entry_bytes, gcm)?;
                return Ok((current_page_id, slot_index, new_head));
            }

            # Check if there's a next page
            if pph.next_posting_page != NULL_PAGE {
                current_page_id = pph.next_posting_page;
            } else {
                # Allocate new page and chain it
                ~new_page_id = self.allocator.allocate_page(FILE_ID_FULLTEXT)?;
                self.init_posting_page(new_page_id, term_hash, gcm)?;

                # Update current page's next pointer
                self.update_next_page(current_page_id, new_page_id, gcm)?;

                # Write entry to new page
                ~new_pph = PostingPageHeader.new(term_hash);
                self.write_entry_to_page(new_page_id, &new_pph, &entry_bytes, gcm)?;
                return Ok((new_page_id, 0, new_head));
            }
        }
    }

    # ========================================================================
    # Soft-delete a PostingEntry (set MVCC expire fields)
    # ========================================================================

    F delete_entry(
        ~self,
        page_id: u32,
        doc_id: u64,
        txn_id: u64,
        cmd_id: u32,
        gcm: &~GroupCommitManager,
    ) -> Result<bool, VaisError> {
        ~page_data = self.pool.get_page_mut(page_id, FILE_ID_FULLTEXT)?;
        ~buf = ByteBuffer.wrap(&page_data);

        # Skip page header
        buf.set_position(PAGE_HEADER_SIZE as usize);

        # Read posting page header
        ~pph = PostingPageHeader.deserialize(&buf)?;

        # Read slot directory and find matching doc_id
        ~slot_dir_start = (PAGE_HEADER_SIZE + POSTING_PAGE_HEADER_SIZE) as usize;
        ~i: u16 = 0;
        L while i < pph.entry_count {
            ~slot_pos = slot_dir_start + (i as usize * SLOT_ENTRY_SIZE as usize);
            buf.set_position(slot_pos);
            ~slot = PostingSlot.deserialize(&buf)?;

            # Read entry at slot offset to check doc_id
            ~entry_pos = (PAGE_HEADER_SIZE + POSTING_PAGE_HEADER_SIZE) as usize
                         + (pph.entry_count as usize * SLOT_ENTRY_SIZE as usize)
                         + slot.offset as usize;
            buf.set_position(entry_pos);
            ~entry = PostingEntry.deserialize(&buf)?;

            if entry.doc_id == doc_id && entry.is_active() {
                # Set expire fields on the entry in-place
                entry.set_expired(txn_id, cmd_id);

                # Write back the modified entry
                ~entry_buf = ByteBuffer.new(entry.serialized_size() as usize);
                entry.serialize(&entry_buf);
                ~entry_bytes = entry_buf.to_vec();

                # Copy entry_bytes back into page at entry_pos
                ~j: usize = 0;
                L while j < entry_bytes.len() {
                    page_data[entry_pos + j] = entry_bytes[j];
                    j += 1;
                }

                self.pool.mark_dirty(page_id)?;
                return Ok(true);
            }

            i += 1;
        }

        Ok(false)
    }

    # ========================================================================
    # Read all posting entries from a posting list (all pages in chain)
    # ========================================================================

    F read_all_entries(
        self,
        head_page_id: u32,
    ) -> Result<Vec<PostingEntry>, VaisError> {
        ~result = Vec.new();

        if head_page_id == NULL_PAGE {
            return Ok(result);
        }

        ~current_page_id = head_page_id;

        L while current_page_id != NULL_PAGE {
            ~entries = self.read_page_entries(current_page_id)?;
            ~next_page = self.get_next_page(current_page_id)?;

            ~i: usize = 0;
            L while i < entries.len() {
                result.push(entries[i].clone());
                i += 1;
            }

            current_page_id = next_page;
        }

        Ok(result)
    }

    # Read all entries from a single posting page
    F read_page_entries(
        self,
        page_id: u32,
    ) -> Result<Vec<PostingEntry>, VaisError> {
        ~result = Vec.new();

        ~page_data = self.pool.get_page(page_id, FILE_ID_FULLTEXT)?;
        ~buf = ByteBuffer.wrap_readonly(&page_data);

        # Skip page header
        buf.set_position(PAGE_HEADER_SIZE as usize);

        # Read posting page header
        ~pph = PostingPageHeader.deserialize(&buf)?;

        # Read slot directory
        ~slot_dir_start = (PAGE_HEADER_SIZE + POSTING_PAGE_HEADER_SIZE) as usize;
        ~data_start = slot_dir_start + (pph.entry_count as usize * SLOT_ENTRY_SIZE as usize);

        ~i: u16 = 0;
        L while i < pph.entry_count {
            ~slot_pos = slot_dir_start + (i as usize * SLOT_ENTRY_SIZE as usize);
            buf.set_position(slot_pos);
            ~slot = PostingSlot.deserialize(&buf)?;

            # Read entry at data offset
            ~entry_pos = data_start + slot.offset as usize;
            buf.set_position(entry_pos);
            ~entry = PostingEntry.deserialize(&buf)?;
            result.push(entry);

            i += 1;
        }

        Ok(result)
    }

    # Get the next page in the posting list chain
    F get_next_page(self, page_id: u32) -> Result<u32, VaisError> {
        ~page_data = self.pool.get_page(page_id, FILE_ID_FULLTEXT)?;
        ~buf = ByteBuffer.wrap_readonly(&page_data);
        buf.set_position(PAGE_HEADER_SIZE as usize);
        ~pph = PostingPageHeader.deserialize(&buf)?;
        Ok(pph.next_posting_page)
    }

    # Get the entry count for a posting page
    F get_entry_count(self, page_id: u32) -> Result<u16, VaisError> {
        ~page_data = self.pool.get_page(page_id, FILE_ID_FULLTEXT)?;
        ~buf = ByteBuffer.wrap_readonly(&page_data);
        buf.set_position(PAGE_HEADER_SIZE as usize);
        ~pph = PostingPageHeader.deserialize(&buf)?;
        Ok(pph.entry_count)
    }

    # ========================================================================
    # Page-level helpers
    # ========================================================================

    # Initialize a new posting list page
    F init_posting_page(
        ~self,
        page_id: u32,
        term_hash: u64,
        gcm: &~GroupCommitManager,
    ) -> Result<(), VaisError> {
        ~page_data = self.pool.get_page_mut(page_id, FILE_ID_FULLTEXT)?;

        # Write page header
        ~ph = PageHeader.new(
            page_id,
            PAGE_TYPE_INVERTED_POSTING,
            ENGINE_TAG_FULLTEXT,
        );
        ~hdr_buf = ByteBuffer.new(PAGE_HEADER_SIZE as usize);
        ph.serialize(&hdr_buf);
        ~hdr_bytes = hdr_buf.to_vec();
        ~j: usize = 0;
        L while j < hdr_bytes.len() {
            page_data[j] = hdr_bytes[j];
            j += 1;
        }

        # Write posting page header
        ~pph = PostingPageHeader.new(term_hash);
        ~pph_buf = ByteBuffer.new(POSTING_PAGE_HEADER_SIZE as usize);
        pph.serialize(&pph_buf);
        ~pph_bytes = pph_buf.to_vec();
        j = 0;
        L while j < pph_bytes.len() {
            page_data[PAGE_HEADER_SIZE as usize + j] = pph_bytes[j];
            j += 1;
        }

        self.pool.mark_dirty(page_id)?;
        Ok(())
    }

    # Write an entry to a posting page (assumes space check was done)
    F write_entry_to_page(
        ~self,
        page_id: u32,
        pph: &PostingPageHeader,
        entry_bytes: &[u8],
        gcm: &~GroupCommitManager,
    ) -> Result<(), VaisError> {
        ~page_data = self.pool.get_page_mut(page_id, FILE_ID_FULLTEXT)?;

        ~new_entry_count = pph.entry_count + 1;

        # Calculate data area start (after all slots including the new one)
        ~slot_dir_start = (PAGE_HEADER_SIZE + POSTING_PAGE_HEADER_SIZE) as usize;
        ~data_start = slot_dir_start + (new_entry_count as usize * SLOT_ENTRY_SIZE as usize);

        # Calculate offset for new entry data (relative to data area start)
        # Walk existing slots to find current data end
        ~data_offset: u16 = 0;
        if pph.entry_count > 0 {
            # Read last slot to find where data ends
            ~buf = ByteBuffer.wrap_readonly(&page_data);
            ~i: u16 = 0;
            L while i < pph.entry_count {
                ~sp = slot_dir_start + (i as usize * SLOT_ENTRY_SIZE as usize);
                buf.set_position(sp);
                ~slot = PostingSlot.deserialize(&buf)?;
                ~end = slot.offset + slot.length;
                if end > data_offset {
                    data_offset = end;
                }
                i += 1;
            }
        }

        # Write the new slot directory entry
        ~new_slot = PostingSlot { offset: data_offset, length: entry_bytes.len() as u16 };
        ~slot_buf = ByteBuffer.new(SLOT_ENTRY_SIZE as usize);
        new_slot.serialize(&slot_buf);
        ~slot_bytes = slot_buf.to_vec();
        ~slot_pos = slot_dir_start + (pph.entry_count as usize * SLOT_ENTRY_SIZE as usize);
        ~j: usize = 0;
        L while j < slot_bytes.len() {
            page_data[slot_pos + j] = slot_bytes[j];
            j += 1;
        }

        # Write entry data
        ~entry_write_pos = data_start + data_offset as usize;
        j = 0;
        L while j < entry_bytes.len() {
            page_data[entry_write_pos + j] = entry_bytes[j];
            j += 1;
        }

        # Update posting page header (increment entry_count)
        ~updated_pph = PostingPageHeader {
            term_hash: pph.term_hash,
            entry_count: new_entry_count,
            next_posting_page: pph.next_posting_page,
            flags: pph.flags,
        };
        ~pph_buf = ByteBuffer.new(POSTING_PAGE_HEADER_SIZE as usize);
        updated_pph.serialize(&pph_buf);
        ~pph_bytes = pph_buf.to_vec();
        j = 0;
        L while j < pph_bytes.len() {
            page_data[PAGE_HEADER_SIZE as usize + j] = pph_bytes[j];
            j += 1;
        }

        self.pool.mark_dirty(page_id)?;
        Ok(())
    }

    # Update the next_posting_page pointer in a page's header
    F update_next_page(
        ~self,
        page_id: u32,
        next_page_id: u32,
        gcm: &~GroupCommitManager,
    ) -> Result<(), VaisError> {
        ~page_data = self.pool.get_page_mut(page_id, FILE_ID_FULLTEXT)?;

        # Read current posting page header
        ~buf = ByteBuffer.wrap_readonly(&page_data);
        buf.set_position(PAGE_HEADER_SIZE as usize);
        ~pph = PostingPageHeader.deserialize(&buf)?;

        # Update next page pointer
        ~updated_pph = PostingPageHeader {
            term_hash: pph.term_hash,
            entry_count: pph.entry_count,
            next_posting_page: next_page_id,
            flags: pph.flags,
        };

        ~pph_buf = ByteBuffer.new(POSTING_PAGE_HEADER_SIZE as usize);
        updated_pph.serialize(&pph_buf);
        ~pph_bytes = pph_buf.to_vec();
        ~j: usize = 0;
        L while j < pph_bytes.len() {
            page_data[PAGE_HEADER_SIZE as usize + j] = pph_bytes[j];
            j += 1;
        }

        self.pool.mark_dirty(page_id)?;
        Ok(())
    }

    # Calculate used space in a posting page (slots + entry data)
    F calculate_used_space(pph: &PostingPageHeader, page_size: u32, page_data: &[u8]) -> u32 {
        if pph.entry_count == 0 {
            return 0;
        }

        ~slot_dir_size = pph.entry_count as u32 * SLOT_ENTRY_SIZE;

        # Calculate total entry data size from slot directory
        ~total_data: u32 = 0;
        ~buf = ByteBuffer.wrap_readonly(page_data);
        ~slot_dir_start = (PAGE_HEADER_SIZE + POSTING_PAGE_HEADER_SIZE) as usize;

        ~i: u16 = 0;
        L while i < pph.entry_count {
            ~sp = slot_dir_start + (i as usize * SLOT_ENTRY_SIZE as usize);
            buf.set_position(sp);
            M PostingSlot.deserialize(&buf) {
                Ok(~slot) => { total_data += slot.length as u32; },
                Err(_) => {},
            }
            i += 1;
        }

        slot_dir_size + total_data
    }

    # Free all pages in a posting list chain
    F free_posting_chain(
        ~self,
        head_page_id: u32,
    ) -> Result<u32, VaisError> {
        ~freed: u32 = 0;
        ~current = head_page_id;

        L while current != NULL_PAGE {
            ~next = self.get_next_page(current)?;
            self.allocator.free_page(current, FILE_ID_FULLTEXT)?;
            freed += 1;
            current = next;
        }

        Ok(freed)
    }
}
