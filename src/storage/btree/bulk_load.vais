# B+Tree Bulk Load
# Efficiently builds a B+Tree from pre-sorted data
# Avoids top-down insert overhead by building bottom-up
# Used for CREATE INDEX, COPY, and initial data load

U storage/constants.{NULL_PAGE, PAGE_HEADER_SIZE};
U storage/error.{VaisError, err_internal};
U storage/buffer/pool.{BufferPool};
U storage/btree/tree.{BTree};
U storage/btree/node.{BTreeInternalNode, BTreeLeafNode};
U storage/btree/entry.{BTreeLeafEntry, BTreeInternalEntry};

# Bulk load entry: pre-sorted (key, tid) pair
S BulkLoadEntry {
    key: Vec<u8>,
    tid: u32,
}

X BulkLoadEntry {
    F new(key: Vec<u8>, tid: u32) -> BulkLoadEntry {
        BulkLoadEntry { key, tid }
    }
}

# Bulk load a B+Tree from sorted entries
# The entries MUST be sorted by key before calling this function
# Returns a new BTree with root_page_id set
F bulk_load(
    entries: &[BulkLoadEntry],
    file_id: u8,
    page_size: u32,
    fill_factor: f64,    # 0.0-1.0, typically 0.9 for bulk load
    pool: &~BufferPool,
) -> Result<BTree, VaisError> {
    I entries.is_empty() {
        # Create empty tree with single leaf root
        ~root_page = pool.allocate_page(file_id)?;
        ~root_frame = pool.fetch_page(file_id, root_page)?;
        ~leaf = BTreeLeafNode.new(root_page, page_size, true);
        ~flushed = leaf.flush();
        pool.write_page(root_frame, flushed)?;
        pool.unpin_page(root_frame, true);
        R Ok(BTree.new(root_page, file_id, page_size));
    }

    # Phase 1: Build leaf level (bottom-up)
    ~leaf_pages = build_leaf_level(entries, file_id, page_size, fill_factor, pool)?;

    I leaf_pages.len() == 1 {
        # Only one leaf page needed â€” it's the root
        ~tree = BTree.new(leaf_pages[0].page_id, file_id, page_size);
        tree.entry_count = entries.len() as u64;
        R Ok(tree);
    }

    # Phase 2: Build internal levels from leaf separators
    ~current_level = leaf_pages;
    ~height: u32 = 1;

    L while current_level.len() > 1 {
        current_level = build_internal_level(&current_level, file_id, page_size, fill_factor, pool)?;
        height += 1;
    }

    # The last remaining page is the root
    ~root_page_id = current_level[0].page_id;
    ~tree = BTree.new(root_page_id, file_id, page_size);
    tree.height = height;
    tree.entry_count = entries.len() as u64;

    Ok(tree)
}

# Info about a page created during bulk load
S PageInfo {
    page_id: u32,
    first_key: Vec<u8>,   # First key in this page (used as separator in parent)
}

# Build the leaf level from sorted entries
F build_leaf_level(
    entries: &[BulkLoadEntry],
    file_id: u8,
    page_size: u32,
    fill_factor: f64,
    pool: &~BufferPool,
) -> Result<Vec<PageInfo>, VaisError> {
    ~pages = Vec.new();
    ~current_page = pool.allocate_page(file_id)?;
    ~current_frame = pool.fetch_page(file_id, current_page)?;
    ~leaf = BTreeLeafNode.new(current_page, page_size, false);
    ~first_key = entries[0].key.clone();
    ~prev_page_id = NULL_PAGE;

    ~body_size = page_size - PAGE_HEADER_SIZE;
    ~target_fill = (body_size as f64 * fill_factor) as u32;

    L entry: entries {
        ~entry_size = 8 + entry.key.len() as u32;  # 8B dir + key data

        # Check if this entry would exceed fill factor
        ~used = leaf.entry_count() as u32 * 8;  # approximate
        I used + entry_size > target_fill && leaf.entry_count() > 0 {
            # Finalize current leaf
            I prev_page_id != NULL_PAGE {
                leaf.set_prev_leaf(prev_page_id);
            }

            ~flushed = leaf.flush();
            pool.write_page(current_frame, flushed)?;
            pool.unpin_page(current_frame, true);

            pages.push(PageInfo {
                page_id: current_page,
                first_key: first_key.clone(),
            });

            # Start new leaf
            prev_page_id = current_page;
            current_page = pool.allocate_page(file_id)?;
            current_frame = pool.fetch_page(file_id, current_page)?;
            leaf = BTreeLeafNode.new(current_page, page_size, false);
            leaf.set_prev_leaf(prev_page_id);
            first_key = entry.key.clone();

            # Update previous leaf's next pointer
            ~prev_frame = pool.fetch_page(file_id, prev_page_id)?;
            ~prev_data = pool.get_page(prev_frame);
            ~prev_leaf = BTreeLeafNode.from_page_data(prev_data, page_size)?;
            prev_leaf.set_next_leaf(current_page);
            ~prev_flushed = prev_leaf.flush();
            pool.write_page(prev_frame, prev_flushed)?;
            pool.unpin_page(prev_frame, true);
        }

        leaf.insert(&entry.key, entry.tid)?;
    }

    # Finalize last leaf
    I prev_page_id != NULL_PAGE {
        leaf.set_prev_leaf(prev_page_id);
    }
    ~flushed = leaf.flush();
    pool.write_page(current_frame, flushed)?;
    pool.unpin_page(current_frame, true);

    pages.push(PageInfo {
        page_id: current_page,
        first_key,
    });

    Ok(pages)
}

# Build one internal level from the child page info
F build_internal_level(
    children: &[PageInfo],
    file_id: u8,
    page_size: u32,
    fill_factor: f64,
    pool: &~BufferPool,
) -> Result<Vec<PageInfo>, VaisError> {
    ~pages = Vec.new();
    ~current_page = pool.allocate_page(file_id)?;
    ~current_frame = pool.fetch_page(file_id, current_page)?;
    ~internal = BTreeInternalNode.new(current_page, page_size, false);

    # First child becomes leftmost_child
    internal.set_leftmost_child(children[0].page_id);
    ~first_key = children[0].first_key.clone();

    ~body_size = page_size - PAGE_HEADER_SIZE - 4;  # -4 for leftmost_child
    ~target_fill = (body_size as f64 * fill_factor) as u32;

    L i: 1..children.len() {
        ~entry_size = 8 + children[i].first_key.len() as u32;

        ~used = internal.entry_count() as u32 * 8;
        I used + entry_size > target_fill && internal.entry_count() > 0 {
            # Finalize current internal node
            ~flushed = internal.flush();
            pool.write_page(current_frame, flushed)?;
            pool.unpin_page(current_frame, true);

            pages.push(PageInfo {
                page_id: current_page,
                first_key: first_key.clone(),
            });

            # Start new internal node
            current_page = pool.allocate_page(file_id)?;
            current_frame = pool.fetch_page(file_id, current_page)?;
            internal = BTreeInternalNode.new(current_page, page_size, false);
            internal.set_leftmost_child(children[i].page_id);
            first_key = children[i].first_key.clone();
            C;
        }

        internal.insert_entry(&children[i].first_key, children[i].page_id)?;
    }

    # Finalize last internal node
    ~flushed = internal.flush();
    pool.write_page(current_frame, flushed)?;
    pool.unpin_page(current_frame, true);

    pages.push(PageInfo {
        page_id: current_page,
        first_key,
    });

    Ok(pages)
}
