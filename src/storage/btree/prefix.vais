# B+Tree Prefix Compression
# Reduces key storage by encoding only suffix relative to previous key
# Based on Stage 1 Section 9 - prefix compression for leaf pages
# Useful for sequential/monotonic keys (timestamps, auto-inc IDs)

U storage/error.{VaisError, err_internal};
U storage/btree/key.{common_prefix_length, strip_prefix, reconstruct_key};
U std/bytes.{ByteBuffer};

# Compressed key entry: prefix_len + suffix
# On-disk format: [u16 prefix_len][u16 suffix_len][suffix bytes]
S CompressedKey {
    prefix_len: u16,     # Bytes shared with previous key
    suffix: Vec<u8>,     # Remaining bytes after prefix
}

X CompressedKey {
    F new(prefix_len: u16, suffix: Vec<u8>) -> CompressedKey {
        CompressedKey { prefix_len, suffix }
    }

    # Serialized size
    F serialized_size(self) -> u32 {
        4 + self.suffix.len() as u32  # 2B prefix_len + 2B suffix_len + suffix
    }

    F serialize(self, buf: &~ByteBuffer) {
        buf.put_u16_le(self.prefix_len);
        buf.put_u16_le(self.suffix.len() as u16);
        buf.put_bytes(&self.suffix);
    }

    F deserialize(buf: &ByteBuffer) -> Result<CompressedKey, VaisError> {
        ~prefix_len = buf.get_u16_le()?;
        ~suffix_len = buf.get_u16_le()?;
        ~suffix = buf.get_bytes(suffix_len as usize)?;
        Ok(CompressedKey { prefix_len, suffix })
    }
}

# Compress a sorted sequence of keys using prefix compression
# Returns compressed keys. First key has prefix_len = 0 (full key stored)
F compress_keys(keys: &[&[u8]]) -> Vec<CompressedKey> {
    ~compressed = Vec.with_capacity(keys.len());

    if keys.is_empty() {
        return compressed;
    }

    # First key is stored in full
    compressed.push(CompressedKey.new(0, keys[0].to_vec()));

    for i in 1..keys.len() {
        ~(prefix_len, suffix) = strip_prefix(keys[i], keys[i - 1]);
        compressed.push(CompressedKey.new(prefix_len, suffix));
    }

    compressed
}

# Decompress a sequence of compressed keys back to full keys
F decompress_keys(compressed: &[CompressedKey]) -> Vec<Vec<u8>> {
    ~keys = Vec.with_capacity(compressed.len());

    if compressed.is_empty() {
        return keys;
    }

    # First key is the full suffix (prefix_len = 0)
    keys.push(compressed[0].suffix.clone());

    for i in 1..compressed.len() {
        ~prev_key = &keys[i - 1];
        ~full_key = reconstruct_key(prev_key, compressed[i].prefix_len, &compressed[i].suffix);
        keys.push(full_key);
    }

    keys
}

# Calculate the total compressed size for a set of sorted keys
F compressed_total_size(keys: &[&[u8]]) -> u32 {
    if keys.is_empty() {
        return 0;
    }

    # First key: 4B header + full key
    ~total: u32 = 4 + keys[0].len() as u32;

    for i in 1..keys.len() {
        ~prefix_len = common_prefix_length(keys[i], keys[i - 1]);
        ~suffix_len = keys[i].len() - prefix_len;
        total += 4 + suffix_len as u32;  # 4B header + suffix
    }

    total
}

# Calculate compression ratio (0.0 = no savings, 1.0 = all prefix)
F compression_ratio(keys: &[&[u8]]) -> f64 {
    if keys.is_empty() || keys.len() == 1 {
        return 0.0;
    }

    ~original_size: u32 = 0;
    for key in keys {
        original_size += key.len() as u32;
    }

    ~comp_size = compressed_total_size(keys);
    if original_size == 0 {
        return 0.0;
    }

    1.0 - (comp_size as f64 / (original_size + keys.len() as u32 * 4) as f64)
}

# Find a key in compressed format at a given index
# Requires decompressing from the beginning (or from last restart point)
F decompress_key_at(compressed: &[CompressedKey], index: usize) -> Result<Vec<u8>, VaisError> {
    if index >= compressed.len() {
        return Err(err_internal("Key index out of bounds"));
    }

    ~current_key = compressed[0].suffix.clone();
    for i in 1..=index {
        current_key = reconstruct_key(&current_key, compressed[i].prefix_len, &compressed[i].suffix);
    }

    Ok(current_key)
}

# Restart point interval for prefix compression
# Every N entries, store a full key (prefix_len = 0) to allow random access
L RESTART_INTERVAL: u16 = 16;

# Compress keys with periodic restart points for random access
# Every RESTART_INTERVAL entries, a full key is stored
F compress_keys_with_restarts(keys: &[&[u8]]) -> (Vec<CompressedKey>, Vec<u16>) {
    ~compressed = Vec.with_capacity(keys.len());
    ~restart_points = Vec.new();

    if keys.is_empty() {
        return (compressed, restart_points);
    }

    for i in 0..keys.len() {
        if (i as u16) % RESTART_INTERVAL == 0 {
            # Restart point: store full key
            restart_points.push(i as u16);
            compressed.push(CompressedKey.new(0, keys[i].to_vec()));
        } else {
            ~(prefix_len, suffix) = strip_prefix(keys[i], keys[i - 1]);
            compressed.push(CompressedKey.new(prefix_len, suffix));
        }
    }

    (compressed, restart_points)
}

# Decompress a key at an arbitrary index using restart points
# Much faster than decompressing from the start for large pages
F decompress_key_with_restarts(
    compressed: &[CompressedKey],
    restart_points: &[u16],
    index: usize,
) -> Result<Vec<u8>, VaisError> {
    if index >= compressed.len() {
        return Err(err_internal("Key index out of bounds"));
    }

    # Find the nearest restart point at or before index
    ~restart_idx: usize = 0;
    for i in 0..restart_points.len() {
        if restart_points[i] as usize <= index {
            restart_idx = restart_points[i] as usize;
        } else {
            break;
        }
    }

    # Decompress from restart point to target index
    ~current_key = compressed[restart_idx].suffix.clone();
    for i in (restart_idx + 1)..=index {
        current_key = reconstruct_key(&current_key, compressed[i].prefix_len, &compressed[i].suffix);
    }

    Ok(current_key)
}
