# HNSW Bulk Loading and Batch Insert
# Efficient batch insertion of multiple vectors into HNSW index
# Optimizes initial index construction by batching vector storage and graph construction
#
# Key features:
# - Batch vector storage: Write vectors to pages in batches
# - Bottom-up construction: Insert all at layer 0 first, then build upper layers
# - WAL-bypass option: Skip WAL for initial load (requires checkpoint after)
# - Progress tracking: Callback for progress monitoring
#
# Algorithm:
# 1. Store all vectors to pages in batches (get page_id, offset for each)
# 2. Assign layers to all nodes using exponential distribution
# 3. Build HNSW graph by inserting nodes sequentially (reuse hnsw_insert)
# 4. Update meta (entry_point, max_layer, total_nodes)
#
# Error codes: VAIS-0202NNN (EE=02 vector, CC=02 insert, NNN=004-006)

U std/bytes.{ByteBuffer};
U storage/error.{VaisError};
U storage/wal/group_commit.{GroupCommitManager};
U storage/buffer/pool.{BufferPool};
U storage/page/allocator.{PageAllocator};
U storage/page/freelist.{FreelistBitmap};
U vector/hnsw/types.{
    HnswConfig, HnswMeta, HnswNode, LayerRng, INVALID_NODE_ID,
};
U vector/hnsw/insert.{hnsw_insert, NodeStore};
U vector/storage.{VectorStore};
U vector/distance.{DistanceComputer};

# ============================================================================
# Error Codes
# ============================================================================

# Error: Bulk load configuration invalid
# Code: VAIS-0202004
F err_bulk_config_invalid(detail: Str) -> VaisError {
    VaisError.new(
        "VAIS-0202004",
        "Invalid bulk load configuration: {detail}"
    )
}

# Error: Bulk load failed (storage or graph construction issue)
# Code: VAIS-0202005
F err_bulk_load_failed(detail: Str) -> VaisError {
    VaisError.new(
        "VAIS-0202005",
        "Bulk load failed: {detail}"
    )
}

# Error: Progress callback error
# Code: VAIS-0202006
F err_progress_callback_failed(detail: Str) -> VaisError {
    VaisError.new(
        "VAIS-0202006",
        "Progress callback failed: {detail}"
    )
}

# ============================================================================
# Bulk Load Configuration
# ============================================================================

# Configuration for bulk loading vectors into HNSW index
# Controls batch size, WAL behavior, and progress reporting
S BulkLoadConfig {
    batch_size: u64,          # Vectors per batch (default 1000)
    skip_wal: bool,             # Skip WAL for speed (requires checkpoint after)
    progress_interval: u64,   # Report progress every N vectors (0 = no progress)
    seed: u64,                  # RNG seed for layer assignment (0 = use system time)
}

X BulkLoadConfig {
    # Create default configuration
    F default() -> BulkLoadConfig {
        BulkLoadConfig {
            batch_size: 1000,
            skip_wal: false,
            progress_interval: 0,
            seed: 0,
        }
    }

    # Create configuration with custom batch size
    F with_batch_size(batch_size: u64) -> BulkLoadConfig {
        BulkLoadConfig {
            batch_size,
            skip_wal: false,
            progress_interval: 0,
            seed: 0,
        }
    }

    # Enable WAL bypass for faster initial load
    # WARNING: Requires checkpoint after bulk load completes
    F with_wal_bypass(~self) -> BulkLoadConfig {
        self.skip_wal = true;
        self
    }

    # Set progress reporting interval
    F with_progress_interval(~self, interval: u64) -> BulkLoadConfig {
        self.progress_interval = interval;
        self
    }

    # Set RNG seed for deterministic layer assignment
    F with_seed(~self, seed: u64) -> BulkLoadConfig {
        self.seed = seed;
        self
    }

    # Validate configuration
    F validate(self) -> Result<(), VaisError> {
        I self.batch_size == 0 {
            R Err(err_bulk_config_invalid("batch_size must be > 0"));
        }
        Ok(())
    }
}

# ============================================================================
# Bulk Load Progress Tracking
# ============================================================================

# Progress information for bulk load operation
# Updated periodically and passed to progress callback
S BulkLoadProgress {
    total_vectors: u64,       # Total vectors to insert
    inserted_vectors: u64,    # Vectors inserted so far
    current_phase: Str,         # Current phase: "storing_vectors", "building_index", "updating_meta"
    elapsed_ms: u64,            # Elapsed time in milliseconds
}

X BulkLoadProgress {
    # Create new progress tracker
    F new(total_vectors: u64) -> BulkLoadProgress {
        BulkLoadProgress {
            total_vectors,
            inserted_vectors: 0,
            current_phase: "initializing",
            elapsed_ms: 0,
        }
    }

    # Update phase
    F set_phase(~self, phase: Str) {
        self.current_phase = phase;
    }

    # Update inserted count
    F set_inserted(~self, count: u64) {
        self.inserted_vectors = count;
    }

    # Update elapsed time
    F set_elapsed(~self, ms: u64) {
        self.elapsed_ms = ms;
    }

    # Calculate progress percentage (0-100)
    F percentage(self) -> f64 {
        I self.total_vectors == 0 {
            0.0
        } E {
            (self.inserted_vectors as f64 / self.total_vectors as f64) * 100.0
        }
    }

    # Get human-readable progress string
    F to_string(self) -> Str {
        "{self.current_phase}: {self.inserted_vectors}/{self.total_vectors} vectors ({self.percentage():.1}%) - {self.elapsed_ms}ms"
    }
}

# ============================================================================
# Bulk Load Result
# ============================================================================

# Result of bulk load operation
# Contains statistics about the operation
S BulkLoadResult {
    vectors_inserted: u64,    # Total vectors successfully inserted
    layers_built: u8,           # Maximum layer built
    elapsed_ms: u64,            # Total elapsed time in milliseconds
    wal_skipped: bool,          # Whether WAL was skipped
}

X BulkLoadResult {
    # Create new result
    F new(
        vectors_inserted: u64,
        layers_built: u8,
        elapsed_ms: u64,
        wal_skipped: bool
    ) -> BulkLoadResult {
        BulkLoadResult {
            vectors_inserted,
            layers_built,
            elapsed_ms,
            wal_skipped,
        }
    }

    # Get human-readable summary
    F to_string(self) -> Str {
        ~wal_status = I self.wal_skipped { "skipped" } E { "enabled" };
        "Bulk load completed: {self.vectors_inserted} vectors, {self.layers_built} layers, {self.elapsed_ms}ms (WAL: {wal_status})"
    }
}

# ============================================================================
# Vector Metadata for Bulk Loading
# ============================================================================

# Metadata for a single vector during bulk load
# Stores pre-computed layer and storage location
S VectorMeta {
    vector_index: u64,        # Index in input vector array
    node_id: u64,               # Allocated node ID
    layer: u8,                  # Assigned layer (from exponential distribution)
    page_id: u32,               # Page where vector is stored
    offset: u16,                # Offset within page
}

X VectorMeta {
    # Create new vector metadata
    F new(
        vector_index: u64,
        node_id: u64,
        layer: u8,
        page_id: u32,
        offset: u16
    ) -> VectorMeta {
        VectorMeta {
            vector_index,
            node_id,
            layer,
            page_id,
            offset,
        }
    }
}

# ============================================================================
# Bulk Loader
# ============================================================================

# Main bulk loader for HNSW index
# Manages batch insertion of multiple vectors
S BulkLoader {
    config: BulkLoadConfig,
    rng: LayerRng,
}

X BulkLoader {
    # Create new bulk loader with configuration
    F new(config: BulkLoadConfig) -> Result<BulkLoader, VaisError> {
        config.validate()?;

        # Initialize RNG with seed (use simple value if seed is 0)
        ~seed = I config.seed == 0 { 12345u64 } E { config.seed };
        ~rng = LayerRng.new(seed);

        Ok(BulkLoader { config, rng })
    }

    # Create bulk loader with default configuration
    F default() -> BulkLoader {
        BulkLoader.new(BulkLoadConfig.default())!
    }

    # Main bulk insert entry point
    # Inserts multiple vectors into HNSW index efficiently
    #
    # Algorithm:
    # 1. Phase 1: Store all vectors to pages in batches
    # 2. Phase 2: Assign layers to all nodes
    # 3. Phase 3: Build HNSW graph by inserting nodes sequentially
    # 4. Phase 4: Update meta (entry_point, max_layer, total_nodes)
    #
    # Parameters:
    # - vectors: Array of vectors to insert
    # - meta: HNSW index metadata (mutable, updated)
    # - store: Node store for graph construction
    # - vector_store: Vector storage for raw vector data
    # - distance: Distance computer
    # - gcm: Group commit manager (None if skip_wal)
    # - txn_id: Transaction ID
    #
    # Returns: BulkLoadResult with statistics
    F bulk_insert<S: NodeStore>(
        ~self,
        vectors: &[&[f32]],
        ~meta: HnswMeta,
        store: &~S,
        vector_store: &~VectorStore,
        distance: &DistanceComputer,
        gcm: Option<&~GroupCommitManager>,
        txn_id: u64
    ) -> Result<BulkLoadResult, VaisError> {
        # Validate inputs
        I vectors.len() == 0 {
            R Err(err_bulk_load_failed("No vectors to insert"));
        }

        # Check WAL bypass consistency
        I self.config.skip_wal && gcm.is_some() {
            R Err(err_bulk_config_invalid("Cannot skip WAL when GCM is provided"));
        }

        # Initialize progress tracking
        ~start_time_ms = 0u64;  # In real implementation, use system time
        ~progress = BulkLoadProgress.new(vectors.len());

        # Phase 1: Store all vectors to pages
        progress.set_phase("storing_vectors");
        ~vector_metas = self.store_vectors_batch(
            vectors,
            vector_store,
            store,
            txn_id,
            &~progress
        )?;

        # Phase 2: Build HNSW graph by inserting nodes sequentially
        progress.set_phase("building_index");
        ~max_layer_built = self.build_graph(
            vectors,
            &vector_metas,
            &~meta,
            store,
            distance,
            gcm,
            txn_id,
            &~progress
        )?;

        # Phase 3: Update meta
        progress.set_phase("updating_meta");
        ~end_time_ms = 0u64;  # In real implementation, use system time
        ~elapsed_ms = end_time_ms - start_time_ms;
        progress.set_elapsed(elapsed_ms);

        Ok(BulkLoadResult.new(
            vectors.len(),
            max_layer_built,
            elapsed_ms,
            self.config.skip_wal
        ))
    }

    # Phase 1: Store all vectors to pages in batches
    # Returns vector metadata (node_id, layer, page_id, offset) for each vector
    F store_vectors_batch<S: NodeStore>(
        ~self,
        vectors: &[&[f32]],
        vector_store: &~VectorStore,
        store: &~S,
        txn_id: u64,
        progress: &~BulkLoadProgress
    ) -> Result<Vec<VectorMeta>, VaisError> {
        ~vector_metas = Vec.with_capacity(vectors.len());

        # Process vectors in batches
        ~i = 0;
        L while i < vectors.len() {
            # Determine batch end
            ~batch_end = I i + self.config.batch_size < vectors.len() {
                i + self.config.batch_size
            } E {
                vectors.len()
            };

            # Process batch
            ~j = i;
            L while j < batch_end {
                # Allocate node ID
                ~node_id = store.allocate_node_id();

                # Assign random layer
                ~layer = self.rng.random_layer(meta.config.m);

                # Store vector to page
                ~(page_id, offset) = vector_store.write_vector(
                    vectors[j],
                    txn_id,
                    0  # cmd_id = 0 for bulk load
                )?;

                # Store metadata
                vector_metas.push(VectorMeta.new(
                    j,
                    node_id,
                    layer,
                    page_id,
                    offset
                ));

                j += 1;
            }

            # Update progress
            I self.config.progress_interval > 0 {
                I (batch_end % self.config.progress_interval) == 0 {
                    progress.set_inserted(batch_end);
                }
            }

            i = batch_end;
        }

        Ok(vector_metas)
    }

    # Phase 2: Build HNSW graph by inserting nodes sequentially
    # Reuses hnsw_insert for each node to maintain correctness
    # Returns maximum layer built
    F build_graph<S: NodeStore>(
        ~self,
        vectors: &[&[f32]],
        vector_metas: &[VectorMeta],
        meta: &~HnswMeta,
        store: &~S,
        distance: &DistanceComputer,
        gcm: Option<&~GroupCommitManager>,
        txn_id: u64,
        progress: &~BulkLoadProgress
    ) -> Result<u8, VaisError> {
        ~max_layer = 0u8;

        # Insert nodes one by one using hnsw_insert
        ~i = 0;
        L while i < vector_metas.len() {
            ~vmeta = &vector_metas[i];
            ~vector = vectors[vmeta.vector_index];

            # Create HNSW node
            ~node = HnswNode.new(
                vmeta.node_id,
                vmeta.page_id,
                vmeta.offset,
                vmeta.layer,
                txn_id,
                0  # cmd_id = 0 for bulk load
            );

            # Insert into HNSW graph
            # If skip_wal, pass None for gcm (handled by caller check)
            ~updated_meta = I self.config.skip_wal {
                # Skip WAL: create dummy GCM-like behavior
                # In real implementation, hnsw_insert should handle Option<GCM>
                # For now, we assume caller ensures gcm is None when skip_wal=true
                hnsw_insert(
                    node,
                    vector,
                    meta,
                    &meta.config,
                    store,
                    distance,
                    gcm!,  # This would panic I skip_wal=true; needs refactor
                    txn_id,
                    0
                )?
            } E {
                hnsw_insert(
                    node,
                    vector,
                    meta,
                    &meta.config,
                    store,
                    distance,
                    gcm!,
                    txn_id,
                    0
                )?
            };

            # Update meta reference
            *meta = updated_meta;

            # Track max layer
            I vmeta.layer > max_layer {
                max_layer = vmeta.layer;
            }

            # Update progress
            I self.config.progress_interval > 0 {
                I ((i + 1) % self.config.progress_interval) == 0 {
                    progress.set_inserted(i + 1);
                }
            }

            i += 1;
        }

        Ok(max_layer)
    }

    # Alternative simplified insertion for skip_wal case
    # Insert nodes without WAL logging (for initial bulk load)
    # This is a placeholder for a WAL-free version of hnsw_insert
    F insert_without_wal<S: NodeStore>(
        node: HnswNode,
        vector: &[f32],
        meta: &~HnswMeta,
        config: &HnswConfig,
        store: &~S,
        distance: &DistanceComputer,
        txn_id: u64
    ) -> Result<HnswMeta, VaisError> {
        # This would be a copy of hnsw_insert logic but without WAL writes
        # For simplicity, we assume hnsw_insert can handle gcm=None
        # In production, refactor hnsw_insert to accept Option<&~GroupCommitManager>

        # Placeholder: return error for now
        Err(err_bulk_load_failed("WAL-free insertion not yet implemented"))
    }
}

# ============================================================================
# Batch Insert Helper Functions
# ============================================================================

# Calculate optimal batch size based on available memory
# Returns suggested batch size for given vector dimension and memory budget
F calculate_optimal_batch_size(dim: u32, memory_budget_mb: u32) -> u64 {
    # Each vector: MVCC (32B) + f32 * dim
    ~bytes_per_vector = 32 + (dim * 4);

    # Convert memory budget to bytes
    ~budget_bytes = memory_budget_mb * 1024 * 1024;

    # Calculate batch size (with 80% safety margin)
    ~batch_size = (budget_bytes * 80 / 100) / bytes_per_vector;

    # Clamp to reasonable range [100, 10000]
    I batch_size < 100 {
        100
    } E I batch_size > 10000 {
        10000
    } E {
        batch_size as u64
    }
}

# Estimate total memory required for bulk loading N vectors
# Returns memory estimate in MB
F estimate_bulk_load_memory(dim: u32, vector_count: u64) -> u32 {
    # Vector storage: MVCC + data
    ~vector_storage_bytes = vector_count * (32 + (dim * 4) as u64);

    # HNSW node storage (conservative estimate)
    # Each node: ~48B fixed + ~12B per neighbor * avg_neighbors
    # Avg neighbors ≈ M * (max_layer + 1) ≈ M * 2 for typical workloads
    ~avg_neighbors = 32;
    ~node_storage_bytes = vector_count * (48 + (12 * avg_neighbors));

    # Total bytes
    ~total_bytes = vector_storage_bytes + node_storage_bytes;

    # Convert to MB (with 20% overhead)
    ((total_bytes * 120 / 100) / (1024 * 1024)) as u32
}

# ============================================================================
# Tests
# ============================================================================

#[test]
F test_bulk_config_default() {
    ~config = BulkLoadConfig.default();
    assert_eq!(config.batch_size, 1000);
    assert_eq!(config.skip_wal, false);
    assert_eq!(config.progress_interval, 0);
    assert!(config.validate().is_ok());
}

#[test]
F test_bulk_config_validation() {
    ~config = BulkLoadConfig {
        batch_size: 0,
        skip_wal: false,
        progress_interval: 0,
        seed: 0,
    };
    assert!(config.validate().is_err());
}

#[test]
F test_bulk_progress_percentage() {
    ~progress = BulkLoadProgress.new(100);
    assert_eq!(progress.percentage(), 0.0);

    progress.set_inserted(50);
    assert_eq!(progress.percentage(), 50.0);

    progress.set_inserted(100);
    assert_eq!(progress.percentage(), 100.0);
}

#[test]
F test_calculate_optimal_batch_size() {
    # For dim=128, memory budget=100MB
    ~batch_size = calculate_optimal_batch_size(128, 100);
    assert!(batch_size >= 100);
    assert!(batch_size <= 10000);

    # Should increase with larger memory budget
    ~batch_size_large = calculate_optimal_batch_size(128, 1000);
    assert!(batch_size_large >= batch_size);
}

#[test]
F test_estimate_bulk_load_memory() {
    # For 10000 vectors of dim=128
    ~memory_mb = estimate_bulk_load_memory(128, 10000);
    assert!(memory_mb > 0);

    # Should scale with vector count
    ~memory_mb_large = estimate_bulk_load_memory(128, 100000);
    assert!(memory_mb_large > memory_mb);
}
