# SQL Parser - Recursive Descent
# Converts a token stream into an AST
# Expression precedence (low to high):
#   OR < AND < NOT < comparison < addition < multiplication < unary < primary
#
# Handles: SELECT (with CTEs, set ops, joins, subqueries, window functions),
#          INSERT, UPDATE, DELETE, CREATE TABLE, DROP TABLE, ALTER TABLE,
#          CREATE INDEX, DROP INDEX, EXPLAIN, BEGIN/COMMIT/ROLLBACK,
#          SET, PREPARE, EXECUTE, CAST, CASE WHEN, BETWEEN, IN, LIKE, EXISTS

U storage/error.{VaisError};
U sql/types.{SqlType, SqlValue};
U sql/parser/token.{Token, TokenKind, Tokenizer};
U sql/parser/ast.{
    Statement, SelectQuery, SelectItem, Cte, SetOperation, SetOpKind,
    TableRef, JoinClause, JoinType, JoinCondition,
    Expr, BinOp, UnaryOp, WhenClause, OrderByItem,
    CreateTableStmt, ColumnDef, CreateIndexStmt, AlterTableStmt, AlterAction,
    InsertStmt, InsertSource, UpdateStmt, Assignment, DeleteStmt,
    SetTarget,
};

# SQL Parser
S Parser {
    tokens: Vec<Token>,
    pos: u64,
}

X Parser {
    # Create a new parser from a token stream
    F new(tokens: Vec<Token>) -> Parser {
        Parser { tokens, pos: 0 }
    }

    # Parse a single SQL statement
    F parse(~self) -> Result<Statement, VaisError> {
        stmt := self.parse_statement()?;
        # Consume optional trailing semicolon
        self.match_token(TokenKind.Semicolon);
        Ok(stmt)
    }

    # Parse multiple SQL statements separated by semicolons
    F parse_all(~self) -> Result<Vec<Statement>, VaisError> {
        ~stmts := Vec.new();

        L {

            I self.is_at_end() { B }
            # Skip stray semicolons between statements
            L {
                I !(self.match_token(TokenKind.Semicolon)) { B }}

            I self.is_at_end() {
                B;
            }

            stmt := self.parse_statement()?;
            stmts.push(stmt);

            # Consume optional semicolon after statement
            self.match_token(TokenKind.Semicolon);
        }

        Ok(stmts)
    }

    # ========================================================================
    # Statement dispatch
    # ========================================================================

    # Dispatch to specific statement parser based on the first token
    F parse_statement(~self) -> Result<Statement, VaisError> {
        M self.peek() {
            TokenKind.Select => {
                query := self.parse_select()?;
                Ok(Statement.Select { query })
            },
            TokenKind.With => {
                # WITH ... SELECT (CTE)
                query := self.parse_select()?;
                Ok(Statement.Select { query })
            },
            TokenKind.Insert => {
                self.advance();
                insert := self.parse_insert()?;
                Ok(Statement.Insert { insert })
            },
            TokenKind.Update => {
                self.advance();
                update := self.parse_update()?;
                Ok(Statement.Update { update })
            },
            TokenKind.Delete => {
                self.advance();
                delete := self.parse_delete()?;
                Ok(Statement.Delete { delete })
            },
            TokenKind.Create => {
                self.advance();
                self.parse_create()
            },
            TokenKind.Drop => {
                self.advance();
                self.parse_drop()
            },
            TokenKind.Alter => {
                self.advance();
                self.expect(TokenKind.Table)?;
                alter := self.parse_alter_table()?;
                Ok(Statement.AlterTable { alter })
            },
            TokenKind.Explain => {
                self.advance();
                ~analyze := false;
                I self.match_token(TokenKind.Analyze) {
                    analyze = true;
                }
                stmt := self.parse_statement()?;
                Ok(Statement.Explain { stmt: Box.new(stmt), analyze })
            },
            TokenKind.Begin => {
                self.advance();
                # Optional TRANSACTION keyword
                self.match_token(TokenKind.Transaction);
                # Optional isolation level (parsed as identifier)
                ~isolation := Option.None;
                I self.check_identifier("ISOLATION") {
                    self.advance();
                    # Expect "LEVEL"
                    I self.check_identifier("LEVEL") {
                        self.advance();
                    }
                    # Read isolation level name (e.g., "SERIALIZABLE", "READ COMMITTED")
                    ~level_str := self.expect_identifier()?;
                    # Handle two-word levels like "READ COMMITTED" or "REPEATABLE READ"
                    I self.check_identifier("COMMITTED") || self.check_identifier("UNCOMMITTED") || self.check_identifier("READ") {
                        second := self.expect_identifier()?;
                        level_str = "{level_str} {second}";
                    }
                    isolation = Option.Some(level_str);
                }
                Ok(Statement.BeginTxn { isolation })
            },
            TokenKind.Commit => {
                self.advance();
                self.match_token(TokenKind.Transaction);
                Ok(Statement.CommitTxn)
            },
            TokenKind.Rollback => {
                self.advance();
                self.match_token(TokenKind.Transaction);
                Ok(Statement.RollbackTxn)
            },
            TokenKind.Set => {
                self.advance();
                self.parse_set_statement()
            },
            _ => {
                # Check for contextual keywords that are identifiers
                I self.check_identifier("PREPARE") {
                    self.advance();
                    R self.parse_prepare();
                }
                I self.check_identifier("EXECUTE") || self.check_identifier("EXEC") {
                    self.advance();
                    R self.parse_execute();
                }
                Err(self.parse_error("expected statement (SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, ALTER, EXPLAIN, BEGIN, COMMIT, ROLLBACK, SET, PREPARE, or EXECUTE)"))
            },
        }
    }

    # ========================================================================
    # SELECT
    # ========================================================================

    # Parse a full SELECT query including CTEs and set operations
    F parse_select(~self) -> Result<SelectQuery, VaisError> {
        # Parse optional WITH clause (CTEs)
        ~ctes := Vec.new();
        I self.match_token(TokenKind.With) {
            ctes = self.parse_cte()?;
        }

        self.expect(TokenKind.Select)?;

        # Parse optional DISTINCT
        ~distinct := false;
        I self.match_token(TokenKind.Distinct) {
            distinct = true;
        }

        # Parse select list
        select_list := self.parse_select_list()?;

        # Parse optional FROM clause
        ~from := Option.None;
        I self.match_token(TokenKind.From) {
            refs := self.parse_from_clause()?;
            from = Option.Some(refs);
        }

        # Parse optional WHERE clause
        where_clause := self.parse_where_clause()?;

        # Parse optional GROUP BY clause
        group_by := self.parse_group_by()?;

        # Parse optional HAVING clause
        having := self.parse_having()?;

        # Parse optional ORDER BY clause
        order_by := self.parse_order_by()?;

        # Parse optional LIMIT/OFFSET
        (limit, offset) := self.parse_limit_offset()?;

        # Build the query
        ~query := SelectQuery {
            ctes,
            select_list,
            from,
            where_clause,
            group_by,
            having,
            order_by,
            limit,
            offset,
            distinct,
            set_op: Option.None,
        };

        # Parse optional set operations (UNION, INTERSECT, EXCEPT)
        query.set_op = self.parse_set_operation()?;

        Ok(query)
    }

    # Parse WITH clause containing one or more CTEs
    F parse_cte(~self) -> Result<Vec<Cte>, VaisError> {
        ~ctes := Vec.new();

        L {
            ~recursive := false;
            I self.match_token(TokenKind.Recursive) {
                recursive = true;
            }

            name := self.expect_identifier()?;

            # Optional column alias list
            ~columns := Vec.new();
            I self.match_token(TokenKind.LParen) {
                L {
                    col := self.expect_identifier()?;
                    columns.push(col);
                    I !self.match_token(TokenKind.Comma) {
                        B;
                    }
                }
                self.expect(TokenKind.RParen)?;
            }

            self.expect(TokenKind.As)?;
            self.expect(TokenKind.LParen)?;
            query := self.parse_select()?;
            self.expect(TokenKind.RParen)?;

            ctes.push(Cte { name, columns, query, recursive });

            I !self.match_token(TokenKind.Comma) {
                B;
            }
        }

        Ok(ctes)
    }

    # Parse the select list (between SELECT and FROM)
    F parse_select_list(~self) -> Result<Vec<SelectItem>, VaisError> {
        ~items := Vec.new();

        L {
            item := self.parse_select_item()?;
            items.push(item);
            I !self.match_token(TokenKind.Comma) {
                B;
            }
        }

        Ok(items)
    }

    # Parse a single select item
    F parse_select_item(~self) -> Result<SelectItem, VaisError> {
        # Check for * (all columns)
        I self.match_token(TokenKind.Star) {
            R Ok(SelectItem.AllColumns);
        }

        # Check for table.* (all columns from table)
        # Peek: identifier DOT STAR
        I self.is_identifier() {
            saved_pos := self.pos;
            table_name := self.expect_identifier()?;
            I self.match_token(TokenKind.Dot) {
                I self.match_token(TokenKind.Star) {
                    R Ok(SelectItem.AllColumnsFrom { table: table_name });
                }
                # Not table.*, backtrack
                self.pos = saved_pos;
            } E {
                # No dot, backtrack and parse as expression
                self.pos = saved_pos;
            }
        }

        # Parse expression with optional alias
        expr := self.parse_expr()?;
        ~alias := Option.None;
        I self.match_token(TokenKind.As) {
            a := self.expect_identifier()?;
            alias = Option.Some(a);
        } E I self.is_identifier() {
            # Alias without AS keyword
            a := self.expect_identifier()?;
            alias = Option.Some(a);
        }

        Ok(SelectItem.Expr { expr, alias })
    }

    # Parse FROM clause (comma-separated table references with joins)
    F parse_from_clause(~self) -> Result<Vec<TableRef>, VaisError> {
        ~refs := Vec.new();

        L {
            table_ref := self.parse_table_ref()?;
            # Check for joins attached to this table reference
            joined := self.parse_joins(table_ref)?;
            refs.push(joined);
            I !self.match_token(TokenKind.Comma) {
                B;
            }
        }

        Ok(refs)
    }

    # Parse a single table reference (table name, subquery, or parenthesized ref)
    F parse_table_ref(~self) -> Result<TableRef, VaisError> {
        # Subquery: (SELECT ...)
        I self.match_token(TokenKind.LParen) {
            query := self.parse_select()?;
            self.expect(TokenKind.RParen)?;
            # Subquery in FROM requires an alias
            self.match_token(TokenKind.As);
            alias := self.expect_identifier()?;
            R Ok(TableRef.Subquery { query: Box.new(query), alias });
        }

        # Check for table-valued function: VECTOR_SEARCH(...), GRAPH_TRAVERSE(...), FULLTEXT_MATCH(...)
        I self.is_identifier() {
            saved_pos := self.pos;
            name := self.expect_identifier()?;
            name_upper := name.to_uppercase();

            # Check if this is a known table-valued function followed by LParen
            I (name_upper == "VECTOR_SEARCH" || name_upper == "GRAPH_TRAVERSE" || name_upper == "FULLTEXT_MATCH")
                && self.check(TokenKind.LParen) {
                # Parse table function: name(args...) AS alias
                self.expect(TokenKind.LParen)?;

                # Parse comma-separated argument expressions
                ~args := Vec.new();
                I !self.check(TokenKind.RParen) {
                    L {
                        arg := self.parse_expr()?;
                        args.push(arg);
                        I !self.match_token(TokenKind.Comma) {
                            B;
                        }
                    }
                }
                self.expect(TokenKind.RParen)?;

                # Parse optional alias
                ~alias := Option.None;
                I self.match_token(TokenKind.As) {
                    a := self.expect_identifier()?;
                    alias = Option.Some(a);
                } E I self.is_identifier() && !self.is_join_keyword() {
                    # Implicit alias (without AS) -- but not if it looks like a JOIN keyword
                    a := self.expect_identifier()?;
                    alias = Option.Some(a);
                }

                R Ok(TableRef.TableFunction { name, args, alias });
            }

            # Not a table function, backtrack and parse as regular table name
            self.pos = saved_pos;
        }

        # Table name with optional alias
        name := self.expect_identifier()?;
        ~alias := Option.None;
        I self.match_token(TokenKind.As) {
            a := self.expect_identifier()?;
            alias = Option.Some(a);
        } E I self.is_identifier() && !self.is_join_keyword() {
            # Implicit alias (without AS) -- but not if it looks like a JOIN keyword
            a := self.expect_identifier()?;
            alias = Option.Some(a);
        }

        Ok(TableRef.Table { name, alias })
    }

    # Parse zero or more joins following a table reference
    F parse_joins(~self, left: TableRef) -> Result<TableRef, VaisError> {
        ~current := left;

        L {
            I self.is_join_keyword() {
                current = self.parse_join(current)?;
            } E {
                B;
            }
        }

        Ok(current)
    }

    # Parse a single JOIN clause
    F parse_join(~self, left: TableRef) -> Result<TableRef, VaisError> {
        # Determine join type
        ~join_type := JoinType.Inner;
        ~is_natural := false;

        # NATURAL keyword
        I self.check_identifier("NATURAL") {
            is_natural = true;
            self.advance();
        }

        M self.peek() {
            TokenKind.Inner => {
                self.advance();
                join_type = JoinType.Inner;
            },
            TokenKind.Left => {
                self.advance();
                join_type = JoinType.Left;
                # Optional OUTER keyword
                I self.check_identifier("OUTER") {
                    self.advance();
                }
            },
            TokenKind.Right => {
                self.advance();
                join_type = JoinType.Right;
                # Optional OUTER keyword
                I self.check_identifier("OUTER") {
                    self.advance();
                }
            },
            TokenKind.Cross => {
                self.advance();
                join_type = JoinType.Cross;
            },
            TokenKind.Join => {
                # Plain JOIN = INNER JOIN
                join_type = JoinType.Inner;
            },
            _ => {
                R Err(self.parse_error("expected JOIN keyword"));
            },
        }

        self.expect(TokenKind.Join)?;

        # Parse the right side table reference
        right := self.parse_table_ref()?;

        # Parse join condition
        ~condition := JoinCondition.Natural;

        I is_natural {
            condition = JoinCondition.Natural;
        } E {
            M join_type {
                JoinType.Cross => {
                    # CROSS JOIN has no condition; use Natural as placeholder
                    R Ok(TableRef.CrossJoin {
                        left: Box.new(left),
                        right: Box.new(right),
                    });
                },
                _ => {
                    I self.match_token(TokenKind.On) {
                        expr := self.parse_expr()?;
                        condition = JoinCondition.On { expr };
                    } E I self.match_token(TokenKind.Using) {
                        self.expect(TokenKind.LParen)?;
                        ~columns := Vec.new();
                        L {
                            col := self.expect_identifier()?;
                            columns.push(col);
                            I !self.match_token(TokenKind.Comma) {
                                B;
                            }
                        }
                        self.expect(TokenKind.RParen)?;
                        condition = JoinCondition.Using { columns };
                    } E {
                        R Err(self.parse_error("expected ON or USING after JOIN"));
                    }
                },
            }
        }

        Ok(TableRef.Join {
            join: JoinClause {
                join_type,
                left: Box.new(left),
                right: Box.new(right),
                condition,
            },
        })
    }

    # Parse optional WHERE clause
    F parse_where_clause(~self) -> Result<Option<Expr>, VaisError> {
        I self.match_token(TokenKind.Where) {
            expr := self.parse_expr()?;
            Ok(Option.Some(expr))
        } E {
            Ok(Option.None)
        }
    }

    # Parse optional GROUP BY clause
    F parse_group_by(~self) -> Result<Vec<Expr>, VaisError> {
        I self.match_token(TokenKind.Group) {
            self.expect(TokenKind.By)?;
            ~exprs := Vec.new();
            L {
                expr := self.parse_expr()?;
                exprs.push(expr);
                I !self.match_token(TokenKind.Comma) {
                    B;
                }
            }
            Ok(exprs)
        } E {
            Ok(Vec.new())
        }
    }

    # Parse optional HAVING clause
    F parse_having(~self) -> Result<Option<Expr>, VaisError> {
        I self.match_token(TokenKind.Having) {
            expr := self.parse_expr()?;
            Ok(Option.Some(expr))
        } E {
            Ok(Option.None)
        }
    }

    # Parse optional ORDER BY clause
    F parse_order_by(~self) -> Result<Vec<OrderByItem>, VaisError> {
        I self.match_token(TokenKind.Order) {
            self.expect(TokenKind.By)?;
            ~items := Vec.new();
            L {
                expr := self.parse_expr()?;
                ~asc := true;
                I self.match_token(TokenKind.Asc) {
                    asc = true;
                } E I self.match_token(TokenKind.Desc) {
                    asc = false;
                }

                # Optional NULLS FIRST / NULLS LAST
                ~nulls_first := Option.None;
                I self.match_token(TokenKind.Nulls) {
                    I self.match_token(TokenKind.First) {
                        nulls_first = Option.Some(true);
                    } E I self.match_token(TokenKind.Last) {
                        nulls_first = Option.Some(false);
                    } E {
                        R Err(self.parse_error("expected FIRST or LAST after NULLS"));
                    }
                }

                items.push(OrderByItem { expr, asc, nulls_first });
                I !self.match_token(TokenKind.Comma) {
                    B;
                }
            }
            Ok(items)
        } E {
            Ok(Vec.new())
        }
    }

    # Parse optional LIMIT and OFFSET clauses
    F parse_limit_offset(~self) -> Result<(Option<Expr>, Option<Expr>), VaisError> {
        ~limit := Option.None;
        ~offset := Option.None;

        I self.match_token(TokenKind.Limit) {
            expr := self.parse_expr()?;
            limit = Option.Some(expr);
        }

        I self.match_token(TokenKind.Offset) {
            expr := self.parse_expr()?;
            offset = Option.Some(expr);
        }

        # Also allow LIMIT after OFFSET if LIMIT was not yet parsed
        I limit.is_none() && self.match_token(TokenKind.Limit) {
            expr := self.parse_expr()?;
            limit = Option.Some(expr);
        }

        Ok((limit, offset))
    }

    # Parse optional set operation (UNION/INTERSECT/EXCEPT)
    F parse_set_operation(~self) -> Result<Option<SetOperation>, VaisError> {
        ~op_kind := Option.None;

        M self.peek() {
            TokenKind.Union => {
                self.advance();
                op_kind = Option.Some(SetOpKind.Union);
            },
            TokenKind.Intersect => {
                self.advance();
                op_kind = Option.Some(SetOpKind.Intersect);
            },
            TokenKind.Except => {
                self.advance();
                op_kind = Option.Some(SetOpKind.Except);
            },
            _ => {
                R Ok(Option.None);
            },
        }

        # Check for ALL
        ~all := false;
        I self.match_token(TokenKind.All) {
            all = true;
        }

        # Parse the right side query
        right := self.parse_select()?;

        M op_kind {
            Option.Some(op) => {
                Ok(Option.Some(SetOperation {
                    op,
                    all,
                    right: Box.new(right),
                }))
            },
            Option.None => Ok(Option.None),
        }
    }

    # ========================================================================
    # INSERT
    # ========================================================================

    # Parse INSERT INTO table [(columns)] VALUES (...) | SELECT ...
    F parse_insert(~self) -> Result<InsertStmt, VaisError> {
        self.expect(TokenKind.Into)?;
        table_name := self.expect_identifier()?;

        # Optional column list
        ~columns := Vec.new();
        I self.match_token(TokenKind.LParen) {
            L {
                col := self.expect_identifier()?;
                columns.push(col);
                I !self.match_token(TokenKind.Comma) {
                    B;
                }
            }
            self.expect(TokenKind.RParen)?;
        }

        # VALUES (...) or SELECT ...
        source := I self.match_token(TokenKind.Values) {
            ~rows := Vec.new();
            L {
                self.expect(TokenKind.LParen)?;
                ~row := Vec.new();
                L {
                    expr := self.parse_expr()?;
                    row.push(expr);
                    I !self.match_token(TokenKind.Comma) {
                        B;
                    }
                }
                self.expect(TokenKind.RParen)?;
                rows.push(row);
                I !self.match_token(TokenKind.Comma) {
                    B;
                }
            }
            InsertSource.Values { rows }
        } E {
            # INSERT ... SELECT
            query := self.parse_select()?;
            InsertSource.Query { query }
        };

        Ok(InsertStmt { table_name, columns, source })
    }

    # ========================================================================
    # UPDATE
    # ========================================================================

    # Parse UPDATE table SET col=val, ... [WHERE ...]
    F parse_update(~self) -> Result<UpdateStmt, VaisError> {
        table_name := self.expect_identifier()?;
        self.expect(TokenKind.Set)?;

        ~assignments := Vec.new();
        L {
            column := self.expect_identifier()?;
            self.expect(TokenKind.Eq)?;
            value := self.parse_expr()?;
            assignments.push(Assignment { column, value });
            I !self.match_token(TokenKind.Comma) {
                B;
            }
        }

        where_clause := self.parse_where_clause()?;

        Ok(UpdateStmt { table_name, assignments, where_clause })
    }

    # ========================================================================
    # DELETE
    # ========================================================================

    # Parse DELETE FROM table [WHERE ...]
    F parse_delete(~self) -> Result<DeleteStmt, VaisError> {
        self.expect(TokenKind.From)?;
        table_name := self.expect_identifier()?;
        where_clause := self.parse_where_clause()?;

        Ok(DeleteStmt { table_name, where_clause })
    }

    # ========================================================================
    # CREATE (TABLE / INDEX)
    # ========================================================================

    # Dispatch CREATE TABLE or CREATE [UNIQUE] INDEX
    F parse_create(~self) -> Result<Statement, VaisError> {
        # CREATE UNIQUE INDEX ...
        I self.match_token(TokenKind.Unique) {
            self.expect(TokenKind.Index)?;
            create := self.parse_create_index_body(true)?;
            R Ok(Statement.CreateIndex { create });
        }

        M self.peek() {
            TokenKind.Table => {
                self.advance();
                create := self.parse_create_table()?;
                Ok(Statement.CreateTable { create })
            },
            TokenKind.Index => {
                self.advance();
                create := self.parse_create_index_body(false)?;
                Ok(Statement.CreateIndex { create })
            },
            _ => {
                Err(self.parse_error("expected TABLE or INDEX after CREATE"))
            },
        }
    }

    # Parse CREATE TABLE [IF NOT EXISTS] name (column_defs...)
    F parse_create_table(~self) -> Result<CreateTableStmt, VaisError> {
        ~if_not_exists := false;

        # Check for IF NOT EXISTS (IF is not a keyword, it is an identifier)
        I self.check_identifier("IF") {
            self.advance();
            self.expect(TokenKind.Not)?;
            I self.check_identifier("EXISTS") {
                self.advance();
            } E {
                R Err(self.parse_error("expected EXISTS after NOT"));
            }
            if_not_exists = true;
        }

        name := self.expect_identifier()?;
        self.expect(TokenKind.LParen)?;

        ~columns := Vec.new();
        L {
            col := self.parse_column_def()?;
            columns.push(col);
            I !self.match_token(TokenKind.Comma) {
                B;
            }
        }
        self.expect(TokenKind.RParen)?;

        Ok(CreateTableStmt { name, columns, if_not_exists })
    }

    # Parse a single column definition: name TYPE [constraints...]
    F parse_column_def(~self) -> Result<ColumnDef, VaisError> {
        name := self.expect_identifier()?;
        data_type := self.parse_data_type()?;

        ~nullable := true;
        ~default_value := Option.None;
        ~is_primary_key := false;
        ~is_unique := false;
        ~check_expr := Option.None;

        # Parse column constraints (can appear in any order, multiple times)
        L {
            I self.match_token(TokenKind.Not) {
                self.expect(TokenKind.Null)?;
                nullable = false;
            } E I self.match_token(TokenKind.Null) {
                nullable = true;
            } E I self.match_token(TokenKind.Primary) {
                self.expect(TokenKind.Key)?;
                is_primary_key = true;
                nullable = false;  # PRIMARY KEY implies NOT NULL
            } E I self.match_token(TokenKind.Unique) {
                is_unique = true;
            } E I self.match_token(TokenKind.Default) {
                expr := self.parse_primary()?;
                default_value = Option.Some(expr);
            } E I self.match_token(TokenKind.Check) {
                self.expect(TokenKind.LParen)?;
                expr := self.parse_expr()?;
                self.expect(TokenKind.RParen)?;
                check_expr = Option.Some(expr);
            } E I self.match_token(TokenKind.References) {
                # REFERENCES table(column) -- parse but ignore for now
                _ref_table := self.expect_identifier()?;
                I self.match_token(TokenKind.LParen) {
                    _ref_col := self.expect_identifier()?;
                    self.expect(TokenKind.RParen)?;
                }
            } E {
                B;
            }
        }

        Ok(ColumnDef {
            name,
            data_type,
            nullable,
            default_value,
            is_primary_key,
            is_unique,
            check_expr,
        })
    }

    # Parse a SQL data type: INT, VARCHAR(n), VECTOR(dim), FLOAT, BOOL, TEXT,
    # BLOB, DATE, TIMESTAMP
    F parse_data_type(~self) -> Result<SqlType, VaisError> {
        M self.peek() {
            TokenKind.Int_Kw => {
                self.advance();
                Ok(SqlType.Int)
            },
            TokenKind.Float_Kw => {
                self.advance();
                Ok(SqlType.Float)
            },
            TokenKind.Bool_Kw => {
                self.advance();
                Ok(SqlType.Bool)
            },
            TokenKind.Varchar => {
                self.advance();
                # VARCHAR requires (max_len)
                self.expect(TokenKind.LParen)?;
                max_len := self.expect_int_literal()? as u32;
                self.expect(TokenKind.RParen)?;
                Ok(SqlType.Varchar { max_len })
            },
            TokenKind.Text_Kw => {
                self.advance();
                Ok(SqlType.Text)
            },
            TokenKind.Blob_Kw => {
                self.advance();
                Ok(SqlType.Blob)
            },
            TokenKind.Date_Kw => {
                self.advance();
                Ok(SqlType.Date)
            },
            TokenKind.Timestamp_Kw => {
                self.advance();
                Ok(SqlType.Timestamp)
            },
            TokenKind.Vector_Kw => {
                self.advance();
                # VECTOR requires (dim)
                self.expect(TokenKind.LParen)?;
                dim := self.expect_int_literal()? as u32;
                self.expect(TokenKind.RParen)?;
                Ok(SqlType.Vector { dim })
            },
            _ => {
                Err(self.parse_error("expected data type (INT, FLOAT, BOOL, VARCHAR, TEXT, BLOB, DATE, TIMESTAMP, VECTOR)"))
            },
        }
    }

    # Parse CREATE INDEX body (after INDEX keyword, unique flag already known)
    F parse_create_index(~self) -> Result<CreateIndexStmt, VaisError> {
        self.parse_create_index_body(false)
    }

    # Parse CREATE [UNIQUE] INDEX [IF NOT EXISTS] name ON table (columns...)
    F parse_create_index_body(~self, unique: bool) -> Result<CreateIndexStmt, VaisError> {
        ~if_not_exists := false;

        # Check for IF NOT EXISTS
        I self.check_identifier("IF") {
            self.advance();
            self.expect(TokenKind.Not)?;
            I self.check_identifier("EXISTS") {
                self.advance();
            } E {
                R Err(self.parse_error("expected EXISTS after NOT"));
            }
            if_not_exists = true;
        }

        name := self.expect_identifier()?;
        self.expect(TokenKind.On)?;
        table_name := self.expect_identifier()?;

        self.expect(TokenKind.LParen)?;
        ~columns := Vec.new();
        L {
            col := self.expect_identifier()?;
            columns.push(col);
            I !self.match_token(TokenKind.Comma) {
                B;
            }
        }
        self.expect(TokenKind.RParen)?;

        Ok(CreateIndexStmt { name, table_name, columns, unique, if_not_exists })
    }

    # ========================================================================
    # DROP (TABLE / INDEX)
    # ========================================================================

    # Dispatch DROP TABLE or DROP INDEX
    F parse_drop(~self) -> Result<Statement, VaisError> {
        M self.peek() {
            TokenKind.Table => {
                self.advance();
                ~if_exists := false;
                I self.check_identifier("IF") {
                    self.advance();
                    I self.check_identifier("EXISTS") {
                        self.advance();
                    } E {
                        R Err(self.parse_error("expected EXISTS after IF"));
                    }
                    if_exists = true;
                }
                name := self.expect_identifier()?;
                Ok(Statement.DropTable { name, if_exists })
            },
            TokenKind.Index => {
                self.advance();
                ~if_exists := false;
                I self.check_identifier("IF") {
                    self.advance();
                    I self.check_identifier("EXISTS") {
                        self.advance();
                    } E {
                        R Err(self.parse_error("expected EXISTS after IF"));
                    }
                    if_exists = true;
                }
                name := self.expect_identifier()?;
                Ok(Statement.DropIndex { name, if_exists })
            },
            _ => {
                Err(self.parse_error("expected TABLE or INDEX after DROP"))
            },
        }
    }

    # ========================================================================
    # ALTER TABLE
    # ========================================================================

    # Parse ALTER TABLE table_name action
    F parse_alter_table(~self) -> Result<AlterTableStmt, VaisError> {
        table_name := self.expect_identifier()?;

        action := I self.match_token(TokenKind.Add) {
            # ADD [COLUMN] column_def
            self.match_token(TokenKind.Column);
            column := self.parse_column_def()?;
            AlterAction.AddColumn { column }
        } E I self.match_token(TokenKind.Drop) {
            # DROP [COLUMN] name
            self.match_token(TokenKind.Column);
            name := self.expect_identifier()?;
            AlterAction.DropColumn { name }
        } E I self.match_token(TokenKind.Rename) {
            # RENAME [COLUMN] old_name TO new_name
            self.match_token(TokenKind.Column);
            old_name := self.expect_identifier()?;
            # Expect TO (parsed as identifier since it is not a keyword)
            I !self.check_identifier("TO") {
                R Err(self.parse_error("expected TO after column name in RENAME"));
            }
            self.advance();
            new_name := self.expect_identifier()?;
            AlterAction.RenameColumn { old_name, new_name }
        } E I self.match_token(TokenKind.Alter) {
            # ALTER [COLUMN] name TYPE new_type
            self.match_token(TokenKind.Column);
            name := self.expect_identifier()?;
            # Expect TYPE (parsed as identifier since not a keyword)
            I !self.check_identifier("TYPE") {
                R Err(self.parse_error("expected TYPE after column name in ALTER COLUMN"));
            }
            self.advance();
            new_type := self.parse_data_type()?;
            AlterAction.AlterColumnType { name, new_type }
        } E {
            R Err(self.parse_error("expected ADD, DROP, RENAME, or ALTER after table name"));
        };

        Ok(AlterTableStmt { table_name, action })
    }

    # ========================================================================
    # SET, PREPARE, EXECUTE
    # ========================================================================

    # Parse SET SESSION|GLOBAL key = value
    F parse_set_statement(~self) -> Result<Statement, VaisError> {
        ~is_global := false;
        I self.check_identifier("SESSION") {
            self.advance();
        } E I self.check_identifier("GLOBAL") {
            self.advance();
            is_global = true;
        }

        key := self.expect_identifier()?;
        self.expect(TokenKind.Eq)?;
        value := self.parse_expr()?;

        target := I is_global {
            SetTarget.Global { key, value }
        } E {
            SetTarget.Session { key, value }
        };

        Ok(Statement.SetExpr { target })
    }

    # Parse PREPARE name AS statement
    F parse_prepare(~self) -> Result<Statement, VaisError> {
        name := self.expect_identifier()?;
        self.expect(TokenKind.As)?;
        stmt := self.parse_statement()?;
        Ok(Statement.Prepare { name, stmt: Box.new(stmt) })
    }

    # Parse EXECUTE name [(params...)]
    F parse_execute(~self) -> Result<Statement, VaisError> {
        name := self.expect_identifier()?;
        ~params := Vec.new();

        I self.match_token(TokenKind.LParen) {
            I !self.check(TokenKind.RParen) {
                L {
                    expr := self.parse_expr()?;
                    params.push(expr);
                    I !self.match_token(TokenKind.Comma) {
                        B;
                    }
                }
            }
            self.expect(TokenKind.RParen)?;
        }

        Ok(Statement.Execute { name, params })
    }

    # ========================================================================
    # Expression parsing (precedence climbing)
    # ========================================================================

    # Entry point for expression parsing
    F parse_expr(~self) -> Result<Expr, VaisError> {
        self.parse_or_expr()
    }

    # OR (lowest precedence)
    F parse_or_expr(~self) -> Result<Expr, VaisError> {
        ~left := self.parse_and_expr()?;

        L {

            I !(self.match_token(TokenKind.Or)) { B }
            right := self.parse_and_expr()?;
            left = Expr.BinaryOp {
                left: Box.new(left),
                op: BinOp.Or,
                right: Box.new(right),
            };
        }

        Ok(left)
    }

    # AND
    F parse_and_expr(~self) -> Result<Expr, VaisError> {
        ~left := self.parse_not_expr()?;

        L {

            I !(self.match_token(TokenKind.And)) { B }
            right := self.parse_not_expr()?;
            left = Expr.BinaryOp {
                left: Box.new(left),
                op: BinOp.And,
                right: Box.new(right),
            };
        }

        Ok(left)
    }

    # NOT (prefix unary)
    F parse_not_expr(~self) -> Result<Expr, VaisError> {
        I self.match_token(TokenKind.Not) {
            operand := self.parse_not_expr()?;
            Ok(Expr.UnaryOp { op: UnaryOp.Not, operand: Box.new(operand) })
        } E {
            self.parse_comparison()
        }
    }

    # Comparison: =, <>, <, >, <=, >=, IS [NOT] NULL, BETWEEN, IN, LIKE, EXISTS
    F parse_comparison(~self) -> Result<Expr, VaisError> {
        # Handle EXISTS (subquery) at comparison level
        I self.match_token(TokenKind.Exists) {
            self.expect(TokenKind.LParen)?;
            query := self.parse_select()?;
            self.expect(TokenKind.RParen)?;
            R Ok(Expr.Exists { query: Box.new(query), negated: false });
        }

        # Handle NOT EXISTS (subquery)
        I self.check(TokenKind.Not) {
            saved_pos := self.pos;
            self.advance();
            I self.match_token(TokenKind.Exists) {
                self.expect(TokenKind.LParen)?;
                query := self.parse_select()?;
                self.expect(TokenKind.RParen)?;
                R Ok(Expr.Exists { query: Box.new(query), negated: true });
            }
            # Not NOT EXISTS, backtrack
            self.pos = saved_pos;
        }

        ~expr := self.parse_addition()?;

        # Check for comparison operators and postfix operators
        L {
            M self.peek() {
                TokenKind.Eq => {
                    self.advance();
                    right := self.parse_addition()?;
                    expr = Expr.BinaryOp { left: Box.new(expr), op: BinOp.Eq, right: Box.new(right) };
                },
                TokenKind.Neq => {
                    self.advance();
                    right := self.parse_addition()?;
                    expr = Expr.BinaryOp { left: Box.new(expr), op: BinOp.Neq, right: Box.new(right) };
                },
                TokenKind.Lt => {
                    self.advance();
                    right := self.parse_addition()?;
                    expr = Expr.BinaryOp { left: Box.new(expr), op: BinOp.Lt, right: Box.new(right) };
                },
                TokenKind.Gt => {
                    self.advance();
                    right := self.parse_addition()?;
                    expr = Expr.BinaryOp { left: Box.new(expr), op: BinOp.Gt, right: Box.new(right) };
                },
                TokenKind.Le => {
                    self.advance();
                    right := self.parse_addition()?;
                    expr = Expr.BinaryOp { left: Box.new(expr), op: BinOp.Le, right: Box.new(right) };
                },
                TokenKind.Ge => {
                    self.advance();
                    right := self.parse_addition()?;
                    expr = Expr.BinaryOp { left: Box.new(expr), op: BinOp.Ge, right: Box.new(right) };
                },
                TokenKind.Is => {
                    self.advance();
                    ~negated := false;
                    I self.match_token(TokenKind.Not) {
                        negated = true;
                    }
                    self.expect(TokenKind.Null)?;
                    expr = Expr.IsNull { expr: Box.new(expr), negated };
                },
                TokenKind.Between => {
                    self.advance();
                    low := self.parse_addition()?;
                    self.expect(TokenKind.And)?;
                    high := self.parse_addition()?;
                    expr = Expr.Between {
                        expr: Box.new(expr),
                        low: Box.new(low),
                        high: Box.new(high),
                        negated: false,
                    };
                },
                TokenKind.Not => {
                    # NOT BETWEEN, NOT IN, NOT LIKE
                    saved_pos := self.pos;
                    self.advance();
                    M self.peek() {
                        TokenKind.Between => {
                            self.advance();
                            low := self.parse_addition()?;
                            self.expect(TokenKind.And)?;
                            high := self.parse_addition()?;
                            expr = Expr.Between {
                                expr: Box.new(expr),
                                low: Box.new(low),
                                high: Box.new(high),
                                negated: true,
                            };
                        },
                        TokenKind.In => {
                            self.advance();
                            expr = self.parse_in_expr(expr, true)?;
                        },
                        TokenKind.Like => {
                            self.advance();
                            pattern := self.parse_addition()?;
                            expr = Expr.Like {
                                expr: Box.new(expr),
                                pattern: Box.new(pattern),
                                negated: true,
                            };
                        },
                        _ => {
                            # Not a postfix NOT, backtrack
                            self.pos = saved_pos;
                            B;
                        },
                    }
                },
                TokenKind.In => {
                    self.advance();
                    expr = self.parse_in_expr(expr, false)?;
                },
                TokenKind.Like => {
                    self.advance();
                    pattern := self.parse_addition()?;
                    expr = Expr.Like {
                        expr: Box.new(expr),
                        pattern: Box.new(pattern),
                        negated: false,
                    };
                },
                _ => {
                    B;
                },
            }
        }

        Ok(expr)
    }

    # Parse IN (list) or IN (subquery) after the IN keyword
    F parse_in_expr(~self, left: Expr, negated: bool) -> Result<Expr, VaisError> {
        self.expect(TokenKind.LParen)?;

        # Distinguish subquery from value list by checking for SELECT/WITH
        M self.peek() {
            TokenKind.Select | TokenKind.With => {
                query := self.parse_select()?;
                self.expect(TokenKind.RParen)?;
                Ok(Expr.InSubquery {
                    expr: Box.new(left),
                    query: Box.new(query),
                    negated,
                })
            },
            _ => {
                ~list := Vec.new();
                I !self.check(TokenKind.RParen) {
                    L {
                        expr := self.parse_expr()?;
                        list.push(expr);
                        I !self.match_token(TokenKind.Comma) {
                            B;
                        }
                    }
                }
                self.expect(TokenKind.RParen)?;
                Ok(Expr.InList {
                    expr: Box.new(left),
                    list,
                    negated,
                })
            },
        }
    }

    # Addition/subtraction and string concatenation (||)
    F parse_addition(~self) -> Result<Expr, VaisError> {
        ~left := self.parse_multiplication()?;

        L {
            M self.peek() {
                TokenKind.Plus => {
                    self.advance();
                    right := self.parse_multiplication()?;
                    left = Expr.BinaryOp { left: Box.new(left), op: BinOp.Add, right: Box.new(right) };
                },
                TokenKind.Minus => {
                    self.advance();
                    right := self.parse_multiplication()?;
                    left = Expr.BinaryOp { left: Box.new(left), op: BinOp.Sub, right: Box.new(right) };
                },
                TokenKind.Pipe => {
                    self.advance();
                    right := self.parse_multiplication()?;
                    left = Expr.Concat { left: Box.new(left), right: Box.new(right) };
                },
                _ => {
                    B;
                },
            }
        }

        Ok(left)
    }

    # Multiplication, division, modulo
    F parse_multiplication(~self) -> Result<Expr, VaisError> {
        ~left := self.parse_unary()?;

        L {
            M self.peek() {
                TokenKind.Star => {
                    self.advance();
                    right := self.parse_unary()?;
                    left = Expr.BinaryOp { left: Box.new(left), op: BinOp.Mul, right: Box.new(right) };
                },
                TokenKind.Slash => {
                    self.advance();
                    right := self.parse_unary()?;
                    left = Expr.BinaryOp { left: Box.new(left), op: BinOp.Div, right: Box.new(right) };
                },
                TokenKind.Percent => {
                    self.advance();
                    right := self.parse_unary()?;
                    left = Expr.BinaryOp { left: Box.new(left), op: BinOp.Mod, right: Box.new(right) };
                },
                _ => {
                    B;
                },
            }
        }

        Ok(left)
    }

    # Unary minus and NOT
    F parse_unary(~self) -> Result<Expr, VaisError> {
        I self.match_token(TokenKind.Minus) {
            operand := self.parse_unary()?;
            R Ok(Expr.UnaryOp { op: UnaryOp.Neg, operand: Box.new(operand) });
        }

        self.parse_primary()
    }

    # Primary expressions: literals, identifiers, function calls, parenthesized
    # expressions, CASE, CAST, subquery, parameter marker, star
    F parse_primary(~self) -> Result<Expr, VaisError> {
        M self.peek() {
            # Integer literal
            TokenKind.IntLit { .. } => {
                tok := self.advance();
                M tok.kind {
                    TokenKind.IntLit { v } => Ok(Expr.Literal { value: SqlValue.IntVal { v } }),
                    _ => Err(self.parse_error("internal error: expected integer literal")),
                }
            },
            # Float literal
            TokenKind.FloatLit { .. } => {
                tok := self.advance();
                M tok.kind {
                    TokenKind.FloatLit { v } => Ok(Expr.Literal { value: SqlValue.FloatVal { v } }),
                    _ => Err(self.parse_error("internal error: expected float literal")),
                }
            },
            # String literal
            TokenKind.StringLit { .. } => {
                tok := self.advance();
                M tok.kind {
                    TokenKind.StringLit { v } => Ok(Expr.Literal { value: SqlValue.StringVal { v } }),
                    _ => Err(self.parse_error("internal error: expected string literal")),
                }
            },
            # TRUE literal
            TokenKind.True_Kw => {
                self.advance();
                Ok(Expr.Literal { value: SqlValue.BoolVal { v: true } })
            },
            # FALSE literal
            TokenKind.False_Kw => {
                self.advance();
                Ok(Expr.Literal { value: SqlValue.BoolVal { v: false } })
            },
            # NULL literal
            TokenKind.Null => {
                self.advance();
                Ok(Expr.Literal { value: SqlValue.Null })
            },
            # Parameter marker ($1, $2, ...)
            TokenKind.Parameter { .. } => {
                tok := self.advance();
                M tok.kind {
                    TokenKind.Parameter { idx } => Ok(Expr.Parameter { idx }),
                    _ => Err(self.parse_error("internal error: expected parameter")),
                }
            },
            # Star (for COUNT(*))
            TokenKind.Star => {
                self.advance();
                Ok(Expr.Star)
            },
            # CASE expression
            TokenKind.Case => {
                self.parse_case_expr()
            },
            # CAST expression
            TokenKind.Cast => {
                self.parse_cast_expr()
            },
            # EXISTS (subquery) -- also handled in comparison, but can appear as primary
            TokenKind.Exists => {
                self.advance();
                self.expect(TokenKind.LParen)?;
                query := self.parse_select()?;
                self.expect(TokenKind.RParen)?;
                Ok(Expr.Exists { query: Box.new(query), negated: false })
            },
            # Aggregate / window function keywords: COUNT, SUM, AVG, MIN, MAX
            TokenKind.Count | TokenKind.Sum | TokenKind.Avg |
            TokenKind.Min | TokenKind.Max => {
                self.parse_aggregate_function()
            },
            # Window function keywords: ROW_NUMBER, RANK, DENSE_RANK
            TokenKind.Row_Number | TokenKind.Rank | TokenKind.Dense_Rank => {
                self.parse_window_function_keyword()
            },
            # Parenthesized expression or scalar subquery
            TokenKind.LParen => {
                self.advance();
                # Check if it is a subquery
                M self.peek() {
                    TokenKind.Select | TokenKind.With => {
                        query := self.parse_select()?;
                        self.expect(TokenKind.RParen)?;
                        Ok(Expr.Subquery { query: Box.new(query) })
                    },
                    _ => {
                        expr := self.parse_expr()?;
                        self.expect(TokenKind.RParen)?;
                        Ok(expr)
                    },
                }
            },
            # Identifier: column reference, table.column, or function call
            TokenKind.Identifier { .. } => {
                self.parse_identifier_expr()
            },
            _ => {
                Err(self.parse_error("expected expression"))
            },
        }
    }

    # Parse an identifier expression: column ref, table.column, or function call
    F parse_identifier_expr(~self) -> Result<Expr, VaisError> {
        name := self.expect_identifier()?;

        # Check for function call: name(...)
        I self.check(TokenKind.LParen) {
            R self.parse_function_call(name);
        }

        # Check for table.column reference
        I self.match_token(TokenKind.Dot) {
            column := self.expect_identifier()?;
            R Ok(Expr.ColumnRef { table: Option.Some(name), column });
        }

        # Plain column reference
        Ok(Expr.ColumnRef { table: Option.None, column: name })
    }

    # Parse a function call: name(args...) with optional DISTINCT and OVER clause
    F parse_function_call(~self, name: Str) -> Result<Expr, VaisError> {
        self.expect(TokenKind.LParen)?;

        # Check for empty arg list
        I self.match_token(TokenKind.RParen) {
            func_expr := Expr.FunctionCall { name, args: Vec.new(), distinct: false };
            # Check for OVER clause (window function)
            R self.maybe_parse_over(func_expr);
        }

        # Check for DISTINCT keyword
        ~distinct := false;
        I self.match_token(TokenKind.Distinct) {
            distinct = true;
        }

        # Check for * (e.g., COUNT(*))
        I self.match_token(TokenKind.Star) {
            self.expect(TokenKind.RParen)?;
            func_expr := Expr.FunctionCall {
                name,
                args: Vec.from([Expr.Star]),
                distinct: false,
            };
            R self.maybe_parse_over(func_expr);
        }

        # Parse argument list
        ~args := Vec.new();
        L {
            arg := self.parse_expr()?;
            args.push(arg);
            I !self.match_token(TokenKind.Comma) {
                B;
            }
        }
        self.expect(TokenKind.RParen)?;

        func_expr := Expr.FunctionCall { name, args, distinct };
        # Check for OVER clause (window function)
        self.maybe_parse_over(func_expr)
    }

    # Parse an aggregate function keyword (COUNT, SUM, AVG, MIN, MAX)
    F parse_aggregate_function(~self) -> Result<Expr, VaisError> {
        tok := self.advance();
        name := M tok.kind {
            TokenKind.Count => "COUNT",
            TokenKind.Sum => "SUM",
            TokenKind.Avg => "AVG",
            TokenKind.Min => "MIN",
            TokenKind.Max => "MAX",
            _ => "UNKNOWN",
        };
        self.parse_function_call(name.to_string())
    }

    # Parse a window function keyword (ROW_NUMBER, RANK, DENSE_RANK)
    F parse_window_function_keyword(~self) -> Result<Expr, VaisError> {
        tok := self.advance();
        name := M tok.kind {
            TokenKind.Row_Number => "ROW_NUMBER",
            TokenKind.Rank => "RANK",
            TokenKind.Dense_Rank => "DENSE_RANK",
            _ => "UNKNOWN",
        };
        self.parse_function_call(name.to_string())
    }

    # If an OVER clause follows, wrap the expression as a WindowFunc
    F maybe_parse_over(~self, func: Expr) -> Result<Expr, VaisError> {
        I !self.match_token(TokenKind.Over) {
            R Ok(func);
        }

        self.expect(TokenKind.LParen)?;

        # Parse optional PARTITION BY
        ~partition_by := Vec.new();
        I self.match_token(TokenKind.Partition) {
            self.expect(TokenKind.By)?;
            L {
                expr := self.parse_expr()?;
                partition_by.push(expr);
                I !self.match_token(TokenKind.Comma) {
                    B;
                }
            }
        }

        # Parse optional ORDER BY
        ~order_by := Vec.new();
        I self.match_token(TokenKind.Order) {
            self.expect(TokenKind.By)?;
            L {
                expr := self.parse_expr()?;
                ~asc := true;
                I self.match_token(TokenKind.Asc) {
                    asc = true;
                } E I self.match_token(TokenKind.Desc) {
                    asc = false;
                }
                ~nulls_first := Option.None;
                I self.match_token(TokenKind.Nulls) {
                    I self.match_token(TokenKind.First) {
                        nulls_first = Option.Some(true);
                    } E I self.match_token(TokenKind.Last) {
                        nulls_first = Option.Some(false);
                    } E {
                        R Err(self.parse_error("expected FIRST or LAST after NULLS"));
                    }
                }
                order_by.push(OrderByItem { expr, asc, nulls_first });
                I !self.match_token(TokenKind.Comma) {
                    B;
                }
            }
        }

        self.expect(TokenKind.RParen)?;

        Ok(Expr.WindowFunc {
            func: Box.new(func),
            partition_by,
            order_by,
        })
    }

    # Parse CASE [operand] WHEN condition THEN result ... [ELSE result] END
    F parse_case_expr(~self) -> Result<Expr, VaisError> {
        self.expect(TokenKind.Case)?;

        # Check for simple CASE (CASE expr WHEN ...) vs searched CASE (CASE WHEN ...)
        ~operand := Option.None;
        I !self.check(TokenKind.When) {
            expr := self.parse_expr()?;
            operand = Option.Some(Box.new(expr));
        }

        # Parse WHEN clauses
        ~when_clauses := Vec.new();
        L {
            I !(self.match_token(TokenKind.When)) { B }
            condition := self.parse_expr()?;
            self.expect(TokenKind.Then)?;
            result := self.parse_expr()?;
            when_clauses.push(WhenClause { condition, result });
        }

        I when_clauses.len() == 0 {
            R Err(self.parse_error("CASE expression must have at least one WHEN clause"));
        }

        # Parse optional ELSE
        ~else_result := Option.None;
        I self.match_token(TokenKind.Else) {
            expr := self.parse_expr()?;
            else_result = Option.Some(Box.new(expr));
        }

        self.expect(TokenKind.End)?;

        Ok(Expr.Case { operand, when_clauses, else_result })
    }

    # Parse CAST(expr AS type)
    F parse_cast_expr(~self) -> Result<Expr, VaisError> {
        self.expect(TokenKind.Cast)?;
        self.expect(TokenKind.LParen)?;
        expr := self.parse_expr()?;
        self.expect(TokenKind.As)?;
        target_type := self.parse_data_type()?;
        self.expect(TokenKind.RParen)?;
        Ok(Expr.Cast { expr: Box.new(expr), target_type })
    }

    # ========================================================================
    # Helper methods
    # ========================================================================

    # Peek at the current token kind without consuming it
    F peek(self) -> &TokenKind {
        I self.pos < self.tokens.len() {
            &self.tokens[self.pos].kind
        } E {
            &TokenKind.Eof
        }
    }

    # Advance to the next token, returning the current one
    F advance(~self) -> &Token {
        tok := &self.tokens[self.pos];
        I self.pos < self.tokens.len() {
            self.pos += 1;
        }
        tok
    }

    # Consume the next token if it matches the expected kind, return error otherwise
    F expect(~self, kind: TokenKind) -> Result<&Token, VaisError> {
        I self.check(kind) {
            Ok(self.advance())
        } E {
            Err(self.parse_error("expected {kind}, got {self.peek()}"))
        }
    }

    # If the current token matches the given kind, consume it and return true;
    # otherwise return false
    F match_token(~self, kind: TokenKind) -> bool {
        I self.check(kind) {
            self.advance();
            true
        } E {
            false
        }
    }

    # Check if the current token matches the given kind (without consuming)
    F check(self, kind: TokenKind) -> bool {
        M (self.peek(), &kind) {
            # For enum variants with data, we compare the discriminant only
            (TokenKind.IntLit { .. }, TokenKind.IntLit { .. }) => true,
            (TokenKind.FloatLit { .. }, TokenKind.FloatLit { .. }) => true,
            (TokenKind.StringLit { .. }, TokenKind.StringLit { .. }) => true,
            (TokenKind.Identifier { .. }, TokenKind.Identifier { .. }) => true,
            (TokenKind.Parameter { .. }, TokenKind.Parameter { .. }) => true,
            (a, b) => a == b,
        }
    }

    # Check if we have reached the end of the token stream
    F is_at_end(self) -> bool {
        M self.peek() {
            TokenKind.Eof => true,
            _ => false,
        }
    }

    # Create a parse error with position information from the current token
    F parse_error(self, msg: Str) -> VaisError {
        I self.pos < self.tokens.len() {
            tok := &self.tokens[self.pos];
            VaisError.new(
                "VAIS-0101001",
                "SQL parse error at line {tok.line}, col {tok.col}: {msg}"
            )
        } E {
            VaisError.new(
                "VAIS-0101001",
                "SQL parse error at end of input: {msg}"
            )
        }
    }

    # Check if the current token is an identifier
    F is_identifier(self) -> bool {
        M self.peek() {
            TokenKind.Identifier { .. } => true,
            _ => false,
        }
    }

    # Check if the current token is an identifier with a specific value (case-insensitive)
    F check_identifier(self, name: &str) -> bool {
        M self.peek() {
            TokenKind.Identifier { v } => v.to_uppercase() == name,
            _ => false,
        }
    }

    # Expect an identifier token and return its string value
    F expect_identifier(~self) -> Result<Str, VaisError> {
        M self.peek() {
            TokenKind.Identifier { .. } => {
                tok := self.advance();
                M tok.kind {
                    TokenKind.Identifier { v } => Ok(v),
                    _ => Err(self.parse_error("internal error: expected identifier")),
                }
            },
            _ => {
                Err(self.parse_error("expected identifier"))
            },
        }
    }

    # Expect an integer literal token and return its value
    F expect_int_literal(~self) -> Result<i64, VaisError> {
        M self.peek() {
            TokenKind.IntLit { .. } => {
                tok := self.advance();
                M tok.kind {
                    TokenKind.IntLit { v } => Ok(v),
                    _ => Err(self.parse_error("internal error: expected integer literal")),
                }
            },
            _ => {
                Err(self.parse_error("expected integer literal"))
            },
        }
    }

    # Check if the current token starts a JOIN keyword sequence
    F is_join_keyword(self) -> bool {
        M self.peek() {
            TokenKind.Join | TokenKind.Inner | TokenKind.Left |
            TokenKind.Right | TokenKind.Cross => true,
            TokenKind.Identifier { v } => v.to_uppercase() == "NATURAL",
            _ => false,
        }
    }
}

# ============================================================================
# Convenience function: tokenize + parse in one step
# ============================================================================

# Parse a SQL string into a list of statements
F parse_sql(sql: Str) -> Result<Vec<Statement>, VaisError> {
    ~tokenizer := Tokenizer.new(sql);
    tokens := tokenizer.tokenize_all()?;
    ~parser := Parser.new(tokens);
    parser.parse_all()
}
