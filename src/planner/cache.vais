# Plan Cache — LRU cache for optimized query plans with prepared statement integration
#
# Features:
# - FNV-1a-based query fingerprinting (normalized AST)
# - LRU eviction (linear scan for 256 entries)
# - DDL invalidation by table name
# - Prepared statement linking
# - Cache statistics (hits, misses, evictions, hit_rate)

U storage/error.{VaisError};
U planner/types.{HybridPlanNode, HybridCost};

# ============================================================================
# FNV-1a Hash Constants
# ============================================================================

L FNV_OFFSET_BASIS: u64 = 0xcbf29ce484222325;
L FNV_PRIME: u64 = 0x100000001b3;

# Hash a string using FNV-1a algorithm
F fnv1a_hash_str(s: &Str) -> u64 {
    ~hash = FNV_OFFSET_BASIS;
    for byte in s.bytes() {
        hash ^= byte as u64;
        hash = hash.wrapping_mul(FNV_PRIME);
    }
    hash
}

# Hash bytes using FNV-1a algorithm
F fnv1a_hash_bytes(bytes: &[u8]) -> u64 {
    ~hash = FNV_OFFSET_BASIS;
    for &byte in bytes {
        hash ^= byte as u64;
        hash = hash.wrapping_mul(FNV_PRIME);
    }
    hash
}

# ============================================================================
# Plan Cache Key — Normalized Query Fingerprint
# ============================================================================

# Query fingerprint key — normalized query hash
#
# Normalization process:
# - Replace all literals with $N parameters
# - Hash the AST structure (not the literal values)
S PlanCacheKey {
    hash: u64,
    normalized_sql: Str,  # For debugging/logging
}

X PlanCacheKey {
    # Create a new cache key from normalized SQL
    F new(normalized_sql: Str) -> PlanCacheKey {
        L hash = fnv1a_hash_str(&normalized_sql);
        PlanCacheKey {
            hash,
            normalized_sql,
        }
    }

    # Create from raw hash (for lookups)
    F from_hash(hash: u64) -> PlanCacheKey {
        PlanCacheKey {
            hash,
            normalized_sql: Str.new(),
        }
    }

    # Check equality by hash
    F eq(&self, other: &PlanCacheKey) -> bool {
        self.hash == other.hash
    }
}

# ============================================================================
# Plan Cache Entry — Cached Plan with LRU Tracking
# ============================================================================

# Cached plan entry with LRU tracking
S PlanCacheEntry {
    key: PlanCacheKey,
    plan: HybridPlanNode,
    cost: HybridCost,
    hit_count: u64,
    created_at: u64,     # Timestamp (monotonic counter)
    last_used: u64,      # Timestamp (monotonic counter)
    tables: Vec<Str>,    # Tables referenced (for invalidation)
    prepared_stmt_name: Option<Str>,  # Linked prepared statement
}

X PlanCacheEntry {
    # Create a new cache entry
    F new(
        key: PlanCacheKey,
        plan: HybridPlanNode,
        cost: HybridCost,
        tables: Vec<Str>,
        timestamp: u64,
    ) -> PlanCacheEntry {
        PlanCacheEntry {
            key,
            plan,
            cost,
            hit_count: 0,
            created_at: timestamp,
            last_used: timestamp,
            tables,
            prepared_stmt_name: None,
        }
    }

    # Mark as used (update last_used and hit_count)
    F touch(~self, timestamp: u64) {
        self.last_used = timestamp;
        self.hit_count += 1;
    }

    # Link to a prepared statement
    F link_prepared(~self, name: Str) {
        self.prepared_stmt_name = Some(name);
    }

    # Check if this entry references a table
    F references_table(self, table_name: &Str) -> bool {
        for t in self.tables.iter() {
            if t == table_name {
                return true;
            }
        }
        false
    }
}

# ============================================================================
# Plan Cache Statistics
# ============================================================================

# Plan cache statistics
S PlanCacheStats {
    hits: u64,
    misses: u64,
    evictions: u64,
    entries: usize,
}

X PlanCacheStats {
    F new() -> PlanCacheStats {
        PlanCacheStats {
            hits: 0,
            misses: 0,
            evictions: 0,
            entries: 0,
        }
    }

    # Calculate hit rate (0.0 - 1.0)
    F hit_rate(self) -> f64 {
        L total = self.hits + self.misses;
        if total == 0 {
            0.0
        } else {
            self.hits as f64 / total as f64
        }
    }
}

# ============================================================================
# Plan Cache — LRU with DDL Invalidation
# ============================================================================

L DEFAULT_MAX_ENTRIES: usize = 256;

# LRU plan cache with DDL invalidation
S PlanCache {
    entries: Vec<PlanCacheEntry>,
    max_entries: usize,
    stats: PlanCacheStats,
    timestamp: u64,  # Monotonic counter for LRU
}

X PlanCache {
    # Create a new plan cache with default capacity (256 entries)
    F new() -> PlanCache {
        PlanCache.with_capacity(DEFAULT_MAX_ENTRIES)
    }

    # Create a new plan cache with custom capacity
    F with_capacity(max_entries: usize) -> PlanCache {
        PlanCache {
            entries: Vec.with_capacity(max_entries),
            max_entries,
            stats: PlanCacheStats.new(),
            timestamp: 0,
        }
    }

    # Get current timestamp and increment
    F next_timestamp(~self) -> u64 {
        L ts = self.timestamp;
        self.timestamp += 1;
        ts
    }

    # Get a cached plan (returns reference)
    F get(~self, key: &PlanCacheKey) -> Option<&HybridPlanNode> {
        L ts = self.next_timestamp();

        # Linear scan (fast enough for 256 entries)
        for ~entry in self.entries.iter_mut() {
            if entry.key.eq(key) {
                entry.touch(ts);
                self.stats.hits += 1;
                return Some(&entry.plan);
            }
        }

        self.stats.misses += 1;
        None
    }

    # Get a cached plan with cost
    F get_with_cost(~self, key: &PlanCacheKey) -> Option<(&HybridPlanNode, &HybridCost)> {
        L ts = self.next_timestamp();

        for ~entry in self.entries.iter_mut() {
            if entry.key.eq(key) {
                entry.touch(ts);
                self.stats.hits += 1;
                return Some((&entry.plan, &entry.cost));
            }
        }

        self.stats.misses += 1;
        None
    }

    # Put a new plan in the cache
    F put(
        ~self,
        key: PlanCacheKey,
        plan: HybridPlanNode,
        cost: HybridCost,
        tables: Vec<Str>,
    ) {
        L ts = self.next_timestamp();

        # Check if key already exists (update case)
        for ~entry in self.entries.iter_mut() {
            if entry.key.eq(&key) {
                entry.plan = plan;
                entry.cost = cost;
                entry.tables = tables;
                entry.touch(ts);
                return;
            }
        }

        # Evict if at capacity
        if self.entries.len() >= self.max_entries {
            self.evict_lru();
        }

        # Insert new entry
        L entry = PlanCacheEntry.new(key, plan, cost, tables, ts);
        self.entries.push(entry);
        self.stats.entries = self.entries.len();
    }

    # Evict the least recently used entry (linear scan)
    F evict_lru(~self) {
        if self.entries.len() == 0 {
            return;
        }

        # Find entry with oldest last_used timestamp
        ~min_idx: usize = 0;
        ~min_last_used = self.entries[0].last_used;

        for i in 1..self.entries.len() {
            if self.entries[i].last_used < min_last_used {
                min_idx = i;
                min_last_used = self.entries[i].last_used;
            }
        }

        self.entries.remove(min_idx);
        self.stats.evictions += 1;
        self.stats.entries = self.entries.len();
    }

    # Invalidate all plans referencing a table (for DDL operations)
    # Returns count of entries removed
    F invalidate_table(~self, table_name: &Str) -> u32 {
        ~removed = 0u32;
        ~i: usize = 0;

        while i < self.entries.len() {
            if self.entries[i].references_table(table_name) {
                self.entries.remove(i);
                removed += 1;
                # Don't increment i — next entry shifted into current position
            } else {
                i += 1;
            }
        }

        self.stats.entries = self.entries.len();
        removed
    }

    # Invalidate all cached plans (for schema changes)
    F invalidate_all(~self) {
        self.entries.clear();
        self.stats.entries = 0;
    }

    # Link a cached plan to a prepared statement
    F link_prepared(~self, key: &PlanCacheKey, name: Str) -> bool {
        for ~entry in self.entries.iter_mut() {
            if entry.key.eq(key) {
                entry.link_prepared(name);
                return true;
            }
        }
        false
    }

    # Get cache statistics
    F stats(self) -> &PlanCacheStats {
        &self.stats
    }

    # Get current cache size
    F len(self) -> usize {
        self.entries.len()
    }

    # Check if cache is empty
    F is_empty(self) -> bool {
        self.entries.len() == 0
    }

    # Get maximum capacity
    F capacity(self) -> usize {
        self.max_entries
    }
}

# ============================================================================
# Query Normalization
# ============================================================================

# Normalize SQL query by replacing literals with $N parameters
#
# Example:
#   "SELECT * FROM users WHERE id = 123 AND name = 'alice'"
#   → "SELECT * FROM users WHERE id = $1 AND name = $2"
F normalize_query(sql: &Str) -> Str {
    # In production, this would:
    # 1. Parse SQL into AST
    # 2. Walk AST and replace IntLiteral/StrLiteral/FloatLiteral with $N
    # 3. Serialize normalized AST back to string
    #
    # Simplified implementation: text-level replacement

    ~normalized = Str.new();
    ~param_idx: u32 = 1;
    ~i: usize = 0;
    L bytes = sql.as_bytes();
    L len = bytes.len();

    while i < len {
        L ch = bytes[i];

        # String literal: 'abc' or "abc"
        if ch == 0x27 || ch == 0x22 {  # ' or "
            L quote = ch;
            i += 1;
            # Skip until closing quote
            while i < len {
                if bytes[i] == quote {
                    i += 1;
                    break;
                }
                if bytes[i] == 0x5C {  # backslash
                    i += 1;  # Skip escaped char
                }
                i += 1;
            }
            normalized.push_str("$");
            normalized.push_str(&param_idx.to_string());
            param_idx += 1;
        }
        # Number literal
        else if ch >= 0x30 && ch <= 0x39 {  # '0'..'9'
            # Skip number
            while i < len {
                L c = bytes[i];
                if (c >= 0x30 && c <= 0x39) || c == 0x2E || c == 0x65 || c == 0x45 {
                    # digit or . or e or E
                    i += 1;
                } else {
                    break;
                }
            }
            normalized.push_str("$");
            normalized.push_str(&param_idx.to_string());
            param_idx += 1;
        }
        # Everything else passes through
        else {
            normalized.push(ch as char);
            i += 1;
        }
    }

    normalized
}

# ============================================================================
# Table Extraction from Plan
# ============================================================================

# Extract tables referenced in a plan
# Walks the HybridPlanNode tree and collects all table names from scan nodes
F extract_tables(plan: &HybridPlanNode) -> Vec<Str> {
    ~tables = Vec.new();

    M plan {
        HybridPlanNode.SqlPlan { plan, .. } => {
            # Would walk SQL PlanNode for table references
        },
        HybridPlanNode.VectorScan { params, .. } => {
            tables.push(params.table_name.clone());
        },
        HybridPlanNode.GraphTraverse { .. } => {
            # Graph traversal doesn't reference a single table
        },
        HybridPlanNode.FullTextScan { params, .. } => {
            tables.push(params.table_name.clone());
        },
        HybridPlanNode.ScoreFusion { left, right, .. } => {
            L left_tables = extract_tables(left);
            L right_tables = extract_tables(right);
            for t in left_tables.iter() { tables.push(t.clone()); }
            for t in right_tables.iter() { tables.push(t.clone()); }
        },
        HybridPlanNode.CrossEngineJoin { left, right, .. } => {
            L left_tables = extract_tables(left);
            L right_tables = extract_tables(right);
            for t in left_tables.iter() { tables.push(t.clone()); }
            for t in right_tables.iter() { tables.push(t.clone()); }
        },
        HybridPlanNode.HybridFilter { input, .. } => {
            tables = extract_tables(input);
        },
        HybridPlanNode.HybridProject { input, .. } => {
            tables = extract_tables(input);
        },
        HybridPlanNode.HybridSort { input, .. } => {
            tables = extract_tables(input);
        },
        HybridPlanNode.HybridLimit { input, .. } => {
            tables = extract_tables(input);
        },
        _ => {},
    }

    tables
}
