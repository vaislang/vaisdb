# copy.vais — Data Import/Export (COPY FROM/TO)
#
# Provides COPY FROM (import CSV/JSON/JSONL/binary) and COPY TO (export).
# Supports graph import ordering validation (nodes before edges).

U std/vec.Vec;
U std/string.Str;
U std/option.{Option, Some, None};
U std/result.{Result, Ok, Err};
U storage/error.{VaisError, ErrorSeverity};

# ============================================================================
# Types
# ============================================================================

# CopyFormat — Supported import/export formats
L CopyFormat = Csv | Json | Jsonl | VectorBinary;

# CopyDirection — Import or export
L CopyDirection = CopyFrom | CopyTo;

# CopyOptions — Configuration for COPY operation
S CopyOptions {
    format: CopyFormat,
    delimiter: u8,              # default 44 = ','
    has_header: bool,           # default true
    null_string: Str,           # default ""
    quote_char: u8,             # default 34 = '"'
    escape_char: u8,            # default 92 = '\\'
    wal_bypass: bool,           # default false (fast bulk import)
    batch_size: u32,            # default 1000
}

# CopyState — Per-operation state
S CopyState {
    direction: CopyDirection,
    table_name: Str,
    columns: Vec<Str>,
    options: CopyOptions,
    rows_processed: u64,
    bytes_processed: u64,
}

# CopyHandler — Main handler for COPY operations
S CopyHandler {
    # Tracks whether nodes have been imported (for graph ordering)
    nodes_imported: bool,
}

# ============================================================================
# CopyOptions Implementation
# ============================================================================

X CopyOptions {
    # Create default CopyOptions
    F default() -> CopyOptions {
        CopyOptions {
            format: CopyFormat.Csv,
            delimiter: 44,          # ','
            has_header: true,
            null_string: "",
            quote_char: 34,         # '"'
            escape_char: 92,        # '\\'
            wal_bypass: false,
            batch_size: 1000,
        }
    }

    # Builder: set format
    F with_format(~self, format: CopyFormat) -> CopyOptions {
        self.format = format;
        self
    }

    # Builder: set delimiter
    F with_delimiter(~self, delimiter: u8) -> CopyOptions {
        self.delimiter = delimiter;
        self
    }

    # Builder: set has_header
    F with_header(~self, has_header: bool) -> CopyOptions {
        self.has_header = has_header;
        self
    }

    # Builder: set null_string
    F with_null_string(~self, null_string: Str) -> CopyOptions {
        self.null_string = null_string;
        self
    }

    # Builder: set quote_char
    F with_quote_char(~self, quote_char: u8) -> CopyOptions {
        self.quote_char = quote_char;
        self
    }

    # Builder: set escape_char
    F with_escape_char(~self, escape_char: u8) -> CopyOptions {
        self.escape_char = escape_char;
        self
    }

    # Builder: set wal_bypass
    F with_wal_bypass(~self, wal_bypass: bool) -> CopyOptions {
        self.wal_bypass = wal_bypass;
        self
    }

    # Builder: set batch_size
    F with_batch_size(~self, batch_size: u32) -> CopyOptions {
        self.batch_size = batch_size;
        self
    }
}

# ============================================================================
# CopyState Implementation
# ============================================================================

X CopyState {
    # Create new CopyState
    F new(
        direction: CopyDirection,
        table_name: Str,
        columns: Vec<Str>,
        options: CopyOptions,
    ) -> CopyState {
        CopyState {
            direction: direction,
            table_name: table_name,
            columns: columns,
            options: options,
            rows_processed: 0,
            bytes_processed: 0,
        }
    }

    # Increment rows processed
    F add_rows(~self, count: u64) {
        self.rows_processed = self.rows_processed + count;
    }

    # Increment bytes processed
    F add_bytes(~self, count: u64) {
        self.bytes_processed = self.bytes_processed + count;
    }
}

# ============================================================================
# CopyHandler Implementation
# ============================================================================

X CopyHandler {
    # Create new CopyHandler
    F new() -> CopyHandler {
        CopyHandler {
            nodes_imported: false,
        }
    }

    # Start COPY FROM operation
    F start_copy_from(
        ~self,
        table: Str,
        columns: Vec<Str>,
        options: CopyOptions,
    ) -> Result<CopyState, VaisError> {
        # Validate table exists (placeholder - would query catalog)
        # For now, just check table name is not empty
        I table.len() == 0 {
            R Err(err_copy_table_not_found(""));
        }

        # Check graph import ordering
        L is_edge_table = table.contains("edge") || table.contains("Edge");
        validate_graph_import_order(&table, is_edge_table, self.nodes_imported)?;

        # Track node table imports
        I !is_edge_table {
            self.nodes_imported = true;
        }

        L state = CopyState.new(
            CopyDirection.CopyFrom,
            table,
            columns,
            options,
        );

        R Ok(state);
    }

    # Process COPY FROM data chunk
    F process_copy_data(
        ~self,
        state: &~CopyState,
        data: &[u8],
    ) -> Result<u64, VaisError> {
        # Placeholder implementation
        # In real implementation, would:
        # 1. Parse data based on state.options.format
        # 2. Validate column count matches state.columns.len()
        # 3. Convert to internal row format
        # 4. Insert rows (optionally bypassing WAL if state.options.wal_bypass)
        # 5. Return number of rows parsed

        M state.options.format {
            CopyFormat.Csv => {
                # Simple CSV parsing (single line for demonstration)
                L fields = parse_csv_line(
                    data,
                    state.options.delimiter,
                    state.options.quote_char,
                );

                L expected_cols = state.columns.len() as u64;
                L actual_cols = fields.len() as u64;

                I actual_cols != expected_cols {
                    R Err(err_copy_column_mismatch(expected_cols, actual_cols));
                }

                # Placeholder: would insert row here
                state.add_rows(1);
                state.add_bytes(data.len() as u64);
                R Ok(1);
            },
            CopyFormat.Json => {
                # Placeholder: would parse JSON object
                state.add_bytes(data.len() as u64);
                R Ok(0);
            },
            CopyFormat.Jsonl => {
                # Placeholder: would parse JSONL (one object per line)
                state.add_bytes(data.len() as u64);
                R Ok(0);
            },
            CopyFormat.VectorBinary => {
                # Placeholder: would parse binary vector format
                state.add_bytes(data.len() as u64);
                R Ok(0);
            },
        }
    }

    # Finish COPY FROM operation
    F finish_copy_from(
        ~self,
        state: &CopyState,
    ) -> Result<u64, VaisError> {
        # Placeholder: would flush any pending batches
        # Return total rows imported
        R Ok(state.rows_processed);
    }

    # Start COPY TO operation
    F start_copy_to(
        ~self,
        table: Str,
        columns: Vec<Str>,
        options: CopyOptions,
    ) -> Result<CopyState, VaisError> {
        # Validate table exists (placeholder)
        I table.len() == 0 {
            R Err(err_copy_table_not_found(""));
        }

        L state = CopyState.new(
            CopyDirection.CopyTo,
            table,
            columns,
            options,
        );

        R Ok(state);
    }

    # Generate COPY TO data chunk
    F generate_copy_data(
        ~self,
        state: &~CopyState,
    ) -> Result<Vec<u8>, VaisError> {
        # Placeholder implementation
        # In real implementation, would:
        # 1. Fetch next batch of rows from table
        # 2. Format as CSV/JSON/JSONL/binary based on state.options.format
        # 3. Update state.rows_processed, state.bytes_processed
        # 4. Return formatted data

        # For now, return empty vector
        L empty: Vec<u8> = Vec.new();
        R Ok(empty);
    }

    # Finish COPY TO operation
    F finish_copy_to(
        ~self,
        state: &CopyState,
    ) -> Result<u64, VaisError> {
        # Return total rows exported
        R Ok(state.rows_processed);
    }
}

# ============================================================================
# CSV Parsing Helper
# ============================================================================

# Parse a single CSV line into fields
# Handles quoted fields containing delimiters
F parse_csv_line(data: &[u8], delimiter: u8, quote_char: u8) -> Vec<Str> {
    L fields: Vec<Str> = Vec.new();
    L current_field: Vec<u8> = Vec.new();
    ~in_quotes = false;
    L len = data.len();
    ~i: usize = 0;

    W i < len {
        L byte = data[i];

        I byte == quote_char {
            # Toggle quote state
            in_quotes = !in_quotes;
        } E I byte == delimiter && !in_quotes {
            # End of field
            L field_str = Str.from_utf8_lossy(&current_field);
            fields.push(field_str);
            current_field.clear();
        } E {
            # Regular character
            current_field.push(byte);
        }

        i = i + 1;
    }

    # Push last field
    I current_field.len() > 0 || len > 0 {
        L field_str = Str.from_utf8_lossy(&current_field);
        fields.push(field_str);
    }

    R fields;
}

# ============================================================================
# Graph Import Ordering Validation
# ============================================================================

# Validate graph import order (nodes before edges)
F validate_graph_import_order(
    table_name: &Str,
    is_edge_table: bool,
    nodes_imported: bool,
) -> Result<(), VaisError> {
    I is_edge_table && !nodes_imported {
        R Err(err_copy_graph_order_violation(table_name.clone()));
    }
    R Ok(());
}

# ============================================================================
# Error Functions
# ============================================================================

# VAIS-0605001: Copy format error
F err_copy_format_error(detail: Str) -> VaisError {
    VaisError.new(
        "VAIS-0605001",
        "Copy format error: {detail}"
    )
}

# VAIS-0605002: Copy table not found
F err_copy_table_not_found(table: Str) -> VaisError {
    VaisError.new(
        "VAIS-0605002",
        "Table not found: {table}"
    ).with_hint("Ensure the table exists before running COPY FROM/TO")
}

# VAIS-0605003: Copy column mismatch
F err_copy_column_mismatch(expected: u64, actual: u64) -> VaisError {
    VaisError.new(
        "VAIS-0605003",
        "Column count mismatch: expected {expected}, got {actual}"
    ).with_hint("Check that the number of columns in the data matches the table schema")
}

# VAIS-0605004: Graph import order violation
F err_copy_graph_order_violation(table: Str) -> VaisError {
    VaisError.new(
        "VAIS-0605004",
        "Graph import order violation: edge table '{table}' cannot be imported before node tables"
    ).with_hint("Import node tables first, then edge tables")
}
