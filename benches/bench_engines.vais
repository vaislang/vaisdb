# Vector, Graph, FullText Engine Benchmarks
# Benchmarks for HNSW, distance computation, quantization, graph traversal,
# tokenization, BM25 scoring, boolean/phrase queries
#
# ROADMAP targets:
# - Vector: ann-benchmarks SIFT-1M recall@10 > 0.95 at 10K QPS, OpenAI-1536 dim < 10ms p99
# - Graph: LDBC Social Network 3-hop < 50ms on 1M nodes
# - Full-text: MS MARCO BM25 accuracy matches pyserini

U benches/harness.{
    BenchmarkHarness, BenchmarkConfig, BenchmarkResult, Timer,
    generate_random_vector, generate_random_vectors, generate_random_text,
};
U std/vec.Vec;
U std/string.Str;
U std/math.{sqrt};

# Vector engine imports
U vector/distance.{DistanceMetric, DistanceComputer, cosine_distance, l2_distance, dot_product_distance};
U vector/hnsw/types.{
    HnswConfig, HnswMeta, HnswNode, HnswNeighbor,
    DEFAULT_M, DEFAULT_M_MAX_0, DEFAULT_EF_CONSTRUCTION, DEFAULT_EF_SEARCH,
    DISTANCE_COSINE, DISTANCE_L2, DISTANCE_DOT_PRODUCT,
};
U vector/quantize/scalar.{ScalarQuantizer};
U vector/quantize/pq.{ProductQuantizer};

# Graph engine imports
U graph/types.{GraphConfig, GraphMeta, AdjEntry, GraphNode, PropertyMap, PropertyValue};
U graph/traversal/bfs.{BfsTraversal, TraversalConfig, TraversalResult};
U graph/traversal/dfs.{DfsTraversal};
U graph/traversal/shortest_path.{ShortestPathFinder, PathResult};

# FullText engine imports
U fulltext/types.{FullTextConfig, PostingEntry};
U fulltext/tokenizer.{Tokenizer, TermFreqInfo};
U fulltext/search/bm25.{BM25Scorer};
U fulltext/search/boolean.{BooleanQueryParser, BooleanQueryExecutor, Query};
U fulltext/search/phrase.{PhraseSearcher, PhraseResult};
U fulltext/index/compression.{vbyte_encode, vbyte_decode, delta_encode_doc_ids, delta_decode_doc_ids};

# ============================================================================
# Vector: Distance Computation Benchmarks
# ============================================================================

# Benchmark: Cosine distance at 128 dimensions
F bench_distance_cosine_128(harness: &~BenchmarkHarness) -> BenchmarkResult {
    ~config = BenchmarkConfig.default(Str.from("vec_cosine_128d"));
    config = config.with_iterations(200);

    ~a = generate_random_vector(128, 42);
    ~b = generate_random_vector(128, 99);

    harness.run_simple(&config, || -> u64 {
        ~ops: u64 = 0;
        ~i: u64 = 0;
        W i < 1000 {
            cosine_distance(&a, &b)!;
            ops += 1;
            i += 1;
        }
        ops
    })
}

# Benchmark: Cosine distance at 256 dimensions
F bench_distance_cosine_256(harness: &~BenchmarkHarness) -> BenchmarkResult {
    ~config = BenchmarkConfig.default(Str.from("vec_cosine_256d"));
    config = config.with_iterations(200);

    ~a = generate_random_vector(256, 42);
    ~b = generate_random_vector(256, 99);

    harness.run_simple(&config, || -> u64 {
        ~ops: u64 = 0;
        ~i: u64 = 0;
        W i < 1000 {
            cosine_distance(&a, &b)!;
            ops += 1;
            i += 1;
        }
        ops
    })
}

# Benchmark: Cosine distance at 1536 dimensions (OpenAI embedding size)
F bench_distance_cosine_1536(harness: &~BenchmarkHarness) -> BenchmarkResult {
    ~config = BenchmarkConfig.default(Str.from("vec_cosine_1536d"));
    config = config.with_iterations(100);

    ~a = generate_random_vector(1536, 42);
    ~b = generate_random_vector(1536, 99);

    harness.run_simple(&config, || -> u64 {
        ~ops: u64 = 0;
        ~i: u64 = 0;
        W i < 500 {
            cosine_distance(&a, &b)!;
            ops += 1;
            i += 1;
        }
        ops
    })
}

# Benchmark: L2 distance at 128 dimensions
F bench_distance_l2_128(harness: &~BenchmarkHarness) -> BenchmarkResult {
    ~config = BenchmarkConfig.default(Str.from("vec_l2_128d"));
    config = config.with_iterations(200);

    ~a = generate_random_vector(128, 42);
    ~b = generate_random_vector(128, 99);

    harness.run_simple(&config, || -> u64 {
        ~ops: u64 = 0;
        ~i: u64 = 0;
        W i < 1000 {
            l2_distance(&a, &b)!;
            ops += 1;
            i += 1;
        }
        ops
    })
}

# Benchmark: Dot product distance at 128 dimensions
F bench_distance_dot_128(harness: &~BenchmarkHarness) -> BenchmarkResult {
    ~config = BenchmarkConfig.default(Str.from("vec_dot_128d"));
    config = config.with_iterations(200);

    ~a = generate_random_vector(128, 42);
    ~b = generate_random_vector(128, 99);

    harness.run_simple(&config, || -> u64 {
        ~ops: u64 = 0;
        ~i: u64 = 0;
        W i < 1000 {
            dot_product_distance(&a, &b)!;
            ops += 1;
            i += 1;
        }
        ops
    })
}

# ============================================================================
# Vector: HNSW Insert Benchmarks
# ============================================================================

# Benchmark: HNSW-like node insertion throughput at 128d
# Simulates the node allocation and neighbor list construction
F bench_hnsw_insert_128d(harness: &~BenchmarkHarness) -> BenchmarkResult {
    ~config = BenchmarkConfig.default(Str.from("hnsw_insert_128d"));
    config = config.with_iterations(30);

    harness.run_simple(&config, || -> u64 {
        # Simulate HNSW insert: generate vectors, compute distances, build neighbor lists
        ~vectors = generate_random_vectors(1000, 128, 42);
        ~nodes: Vec<HnswNode> = Vec.new();
        ~inserted: u64 = 0;

        ~i: u64 = 0;
        W i < vectors.len() {
            ~node = HnswNode.new(i, 0, 0, 0, i + 1, 0);
            nodes.push(node);

            # Simulate nearest neighbor search for first 16 neighbors
            I i > 0 {
                ~best_dist: f64 = 999999.0;
                ~j: u64 = 0;
                ~search_limit = I i < 16 { i } E { 16 };
                W j < search_limit {
                    ~dist = cosine_distance(&vectors[i], &vectors[j])!;
                    I dist < best_dist { best_dist = dist; }
                    j += 1;
                }
            }

            inserted += 1;
            i += 1;
        }
        inserted
    })
}

# Benchmark: HNSW-like node insertion throughput at 1536d
F bench_hnsw_insert_1536d(harness: &~BenchmarkHarness) -> BenchmarkResult {
    ~config = BenchmarkConfig.default(Str.from("hnsw_insert_1536d"));
    config = config.with_iterations(10);

    harness.run_simple(&config, || -> u64 {
        ~vectors = generate_random_vectors(200, 1536, 42);
        ~inserted: u64 = 0;

        ~i: u64 = 0;
        W i < vectors.len() {
            I i > 0 {
                ~best_dist: f64 = 999999.0;
                ~j: u64 = 0;
                ~search_limit = I i < 16 { i } E { 16 };
                W j < search_limit {
                    ~dist = cosine_distance(&vectors[i], &vectors[j])!;
                    I dist < best_dist { best_dist = dist; }
                    j += 1;
                }
            }
            inserted += 1;
            i += 1;
        }
        inserted
    })
}

# ============================================================================
# Vector: HNSW Search (Recall vs Latency)
# ============================================================================

# Benchmark: HNSW-like search simulation (brute-force kNN as baseline)
F bench_hnsw_search_recall(harness: &~BenchmarkHarness) -> BenchmarkResult {
    ~config = BenchmarkConfig.default(Str.from("hnsw_search_brute_knn"));
    config = config.with_iterations(50);

    # Pre-build dataset
    ~dataset = generate_random_vectors(5000, 128, 42);

    harness.run_simple(&config, || -> u64 {
        # Brute-force kNN for recall@10 baseline
        ~query = generate_random_vector(128, 9999);
        ~k: u64 = 10;

        # Compute all distances
        ~dists: Vec<(u64, f64)> = Vec.new();
        ~i: u64 = 0;
        W i < dataset.len() {
            ~d = cosine_distance(&query, &dataset[i])!;
            dists.push((i, d));
            i += 1;
        }

        # Partial sort to find top-k (selection sort on first k elements)
        ~ki: u64 = 0;
        W ki < k && ki < dists.len() {
            ~min_idx = ki;
            ~j: u64 = ki + 1;
            W j < dists.len() {
                I dists[j].1 < dists[min_idx].1 {
                    min_idx = j;
                }
                j += 1;
            }
            I min_idx != ki {
                ~tmp = dists[ki];
                dists[ki] = dists[min_idx];
                dists[min_idx] = tmp;
            }
            ki += 1;
        }

        k
    })
}

# ============================================================================
# Vector: Quantization Benchmarks
# ============================================================================

# Benchmark: Scalar quantization encode throughput
F bench_sq_encode(harness: &~BenchmarkHarness) -> BenchmarkResult {
    ~config = BenchmarkConfig.default(Str.from("vec_sq_encode_128d"));
    config = config.with_iterations(100);

    # Train quantizer
    ~train_vectors = generate_random_vectors(100, 128, 42);
    ~quantizer = ScalarQuantizer.new(128);
    ~train_refs: Vec<&[f32]> = Vec.new();
    ~i: u64 = 0;
    W i < train_vectors.len() {
        train_refs.push(&train_vectors[i]);
        i += 1;
    }
    quantizer.train(&train_refs)!;

    ~test_vector = generate_random_vector(128, 999);

    harness.run_simple(&config, || -> u64 {
        ~ops: u64 = 0;
        ~i: u64 = 0;
        W i < 10000 {
            quantizer.encode(&test_vector)!;
            ops += 1;
            i += 1;
        }
        ops
    })
}

# Benchmark: Scalar quantization distance computation
F bench_sq_distance(harness: &~BenchmarkHarness) -> BenchmarkResult {
    ~config = BenchmarkConfig.default(Str.from("vec_sq_distance_128d"));
    config = config.with_iterations(100);

    # Train and encode two vectors
    ~train_vectors = generate_random_vectors(100, 128, 42);
    ~quantizer = ScalarQuantizer.new(128);
    ~train_refs: Vec<&[f32]> = Vec.new();
    ~i: u64 = 0;
    W i < train_vectors.len() {
        train_refs.push(&train_vectors[i]);
        i += 1;
    }
    quantizer.train(&train_refs)!;

    ~a = generate_random_vector(128, 1);
    ~b = generate_random_vector(128, 2);
    ~qa = quantizer.encode(&a)!;
    ~qb = quantizer.encode(&b)!;

    harness.run_simple(&config, || -> u64 {
        ~ops: u64 = 0;
        ~i: u64 = 0;
        W i < 10000 {
            quantizer.quantized_distance(&qa, &qb)!;
            ops += 1;
            i += 1;
        }
        ops
    })
}

# ============================================================================
# Graph: Node/Edge Creation Throughput
# ============================================================================

# Benchmark: Graph node creation throughput (in-memory simulation)
F bench_graph_node_create(harness: &~BenchmarkHarness) -> BenchmarkResult {
    ~config = BenchmarkConfig.default(Str.from("graph_node_create"));
    config = config.with_iterations(50);

    harness.run_simple(&config, || -> u64 {
        ~nodes: Vec<GraphNode> = Vec.new();
        ~created: u64 = 0;
        ~i: u64 = 0;
        W i < 10000 {
            ~labels: Vec<u16> = Vec.new();
            labels.push((i % 10) as u16);
            ~node = GraphNode.new(i, labels, i + 1, 0);
            nodes.push(node);
            created += 1;
            i += 1;
        }
        created
    })
}

# Benchmark: Graph edge creation throughput (adjacency entry creation)
F bench_graph_edge_create(harness: &~BenchmarkHarness) -> BenchmarkResult {
    ~config = BenchmarkConfig.default(Str.from("graph_edge_create"));
    config = config.with_iterations(50);

    harness.run_simple(&config, || -> u64 {
        ~edges: Vec<AdjEntry> = Vec.new();
        ~created: u64 = 0;
        ~i: u64 = 0;
        W i < 10000 {
            ~entry = AdjEntry.new(
                (i + 1) % 10000,  # target_node
                i,                 # edge_id
                (i % 5) as u16,   # edge_type_id
                i + 1,            # txn_id
                0,                 # cmd_id
            );
            edges.push(entry);
            created += 1;
            i += 1;
        }
        created
    })
}

# ============================================================================
# Graph: BFS/DFS Traversal Benchmarks
# ============================================================================

# Benchmark: BFS traversal simulation (depth 1-5 on adjacency list)
# Simulates BFS over an in-memory adjacency list structure
F bench_graph_bfs(harness: &~BenchmarkHarness) -> BenchmarkResult {
    ~config = BenchmarkConfig.default(Str.from("graph_bfs_depth5"));
    config = config.with_iterations(30);

    # Build adjacency list: each node has ~5 outgoing edges
    ~node_count: u64 = 10000;
    ~adj_list: Vec<Vec<u64>> = Vec.new();
    ~i: u64 = 0;
    W i < node_count {
        ~neighbors: Vec<u64> = Vec.new();
        ~state = i * 6364136223846793005 + 1442695040888963407;
        ~j: u64 = 0;
        W j < 5 {
            state = state * 6364136223846793005 + 1442695040888963407;
            ~target = (state >> 33) % node_count;
            neighbors.push(target);
            j += 1;
        }
        adj_list.push(neighbors);
        i += 1;
    }

    harness.run_simple(&config, || -> u64 {
        # BFS from node 0, max depth 5
        U std/hashmap.HashMap;

        ~visited: HashMap<u64, bool> = HashMap.new();
        ~queue: Vec<(u64, u64)> = Vec.new();  # (node_id, depth)
        queue.push((0, 0));
        visited.insert(0, true);
        ~nodes_visited: u64 = 0;

        W queue.len() > 0 {
            ~(current, depth) = queue[0];
            # Remove front (shift)
            ~new_queue: Vec<(u64, u64)> = Vec.new();
            ~qi: u64 = 1;
            W qi < queue.len() {
                new_queue.push(queue[qi]);
                qi += 1;
            }
            queue = new_queue;

            nodes_visited += 1;

            I depth < 5 {
                ~ni: u64 = 0;
                W ni < adj_list[current].len() {
                    ~neighbor = adj_list[current][ni];
                    I !visited.contains_key(&neighbor) {
                        visited.insert(neighbor, true);
                        queue.push((neighbor, depth + 1));
                    }
                    ni += 1;
                }
            }
        }
        nodes_visited
    })
}

# Benchmark: DFS traversal simulation (depth 1-5)
F bench_graph_dfs(harness: &~BenchmarkHarness) -> BenchmarkResult {
    ~config = BenchmarkConfig.default(Str.from("graph_dfs_depth5"));
    config = config.with_iterations(30);

    # Build adjacency list (same as BFS)
    ~node_count: u64 = 10000;
    ~adj_list: Vec<Vec<u64>> = Vec.new();
    ~i: u64 = 0;
    W i < node_count {
        ~neighbors: Vec<u64> = Vec.new();
        ~state = i * 6364136223846793005 + 1442695040888963407;
        ~j: u64 = 0;
        W j < 5 {
            state = state * 6364136223846793005 + 1442695040888963407;
            ~target = (state >> 33) % node_count;
            neighbors.push(target);
            j += 1;
        }
        adj_list.push(neighbors);
        i += 1;
    }

    harness.run_simple(&config, || -> u64 {
        # DFS from node 0, max depth 5
        U std/hashmap.HashMap;

        ~visited: HashMap<u64, bool> = HashMap.new();
        ~stack: Vec<(u64, u64)> = Vec.new();  # (node_id, depth)
        stack.push((0, 0));
        ~nodes_visited: u64 = 0;

        W stack.len() > 0 {
            ~last_idx = stack.len() - 1;
            ~(current, depth) = stack[last_idx];
            stack.truncate(last_idx);

            I visited.contains_key(&current) {
                # Skip already visited
            } E {
                visited.insert(current, true);
                nodes_visited += 1;

                I depth < 5 {
                    ~ni: u64 = 0;
                    W ni < adj_list[current].len() {
                        ~neighbor = adj_list[current][ni];
                        I !visited.contains_key(&neighbor) {
                            stack.push((neighbor, depth + 1));
                        }
                        ni += 1;
                    }
                }
            }
        }
        nodes_visited
    })
}

# ============================================================================
# Graph: Shortest Path (Dijkstra) Benchmark
# ============================================================================

# Benchmark: Dijkstra shortest path simulation
F bench_graph_shortest_path(harness: &~BenchmarkHarness) -> BenchmarkResult {
    ~config = BenchmarkConfig.default(Str.from("graph_dijkstra_10k"));
    config = config.with_iterations(20);

    # Build weighted adjacency list
    ~node_count: u64 = 10000;
    ~adj_list: Vec<Vec<(u64, f64)>> = Vec.new();  # (target, weight)
    ~i: u64 = 0;
    W i < node_count {
        ~neighbors: Vec<(u64, f64)> = Vec.new();
        ~state = i * 6364136223846793005 + 1442695040888963407;
        ~j: u64 = 0;
        W j < 5 {
            state = state * 6364136223846793005 + 1442695040888963407;
            ~target = (state >> 33) % node_count;
            ~weight = ((state >> 48) % 100 + 1) as f64;
            neighbors.push((target, weight));
            j += 1;
        }
        adj_list.push(neighbors);
        i += 1;
    }

    harness.run_simple(&config, || -> u64 {
        # Dijkstra from node 0 to node 5000
        U std/hashmap.HashMap;

        ~dist: HashMap<u64, f64> = HashMap.new();
        ~processed: HashMap<u64, bool> = HashMap.new();
        dist.insert(0, 0.0);

        # Simple Dijkstra (linear scan for min — not heap, just benchmark)
        ~found = false;
        ~iterations: u64 = 0;
        ~max_iterations: u64 = 5000;  # Limit to prevent excessive runtime

        W !found && iterations < max_iterations {
            # Find unprocessed node with minimum distance
            ~min_node: u64 = 0;
            ~min_dist: f64 = 999999999.0;
            ~has_candidate = false;

            L (node, d): dist.iter() {
                I !processed.contains_key(node) && *d < min_dist {
                    min_node = *node;
                    min_dist = *d;
                    has_candidate = true;
                }
            }

            I !has_candidate {
                found = true;
            } E {
                I min_node == 5000 {
                    found = true;
                } E {
                    processed.insert(min_node, true);

                    # Relax neighbors
                    ~ni: u64 = 0;
                    W ni < adj_list[min_node].len() {
                        ~(target, weight) = adj_list[min_node][ni];
                        ~new_dist = min_dist + weight;
                        ~current_dist = M dist.get(&target) {
                            Some(~d) => *d,
                            None => 999999999.0,
                        };
                        I new_dist < current_dist {
                            dist.insert(target, new_dist);
                        }
                        ni += 1;
                    }
                }
            }
            iterations += 1;
        }
        iterations
    })
}

# ============================================================================
# FullText: Tokenization Benchmarks
# ============================================================================

# Benchmark: Tokenization throughput (documents per second)
F bench_tokenize_throughput(harness: &~BenchmarkHarness) -> BenchmarkResult {
    ~config = BenchmarkConfig.default(Str.from("ft_tokenize_docs"));
    config = config.with_iterations(50);

    ~ft_config = FullTextConfig.default();
    ~tokenizer = Tokenizer.from_config(&ft_config);

    # Pre-generate documents
    ~docs: Vec<Str> = Vec.new();
    ~i: u64 = 0;
    W i < 100 {
        docs.push(generate_random_text(200, i + 1));
        i += 1;
    }

    harness.run_simple(&config, || -> u64 {
        ~tokenized: u64 = 0;
        ~i: u64 = 0;
        W i < docs.len() {
            tokenizer.tokenize(&docs[i]);
            tokenized += 1;
            i += 1;
        }
        tokenized
    })
}

# Benchmark: Tokenization with frequency counting
F bench_tokenize_with_freqs(harness: &~BenchmarkHarness) -> BenchmarkResult {
    ~config = BenchmarkConfig.default(Str.from("ft_tokenize_freqs"));
    config = config.with_iterations(50);

    ~ft_config = FullTextConfig.default();
    ~tokenizer = Tokenizer.from_config(&ft_config);

    ~docs: Vec<Str> = Vec.new();
    ~i: u64 = 0;
    W i < 100 {
        docs.push(generate_random_text(200, i + 1));
        i += 1;
    }

    harness.run_simple(&config, || -> u64 {
        ~tokenized: u64 = 0;
        ~i: u64 = 0;
        W i < docs.len() {
            tokenizer.tokenize_with_freqs(&docs[i]);
            tokenized += 1;
            i += 1;
        }
        tokenized
    })
}

# ============================================================================
# FullText: BM25 Scoring Benchmark
# ============================================================================

# Benchmark: BM25 score computation throughput
F bench_bm25_scoring(harness: &~BenchmarkHarness) -> BenchmarkResult {
    ~config = BenchmarkConfig.default(Str.from("ft_bm25_scoring"));
    config = config.with_iterations(100);

    ~scorer = BM25Scorer.with_params(1.2, 0.75);

    harness.run_simple(&config, || -> u64 {
        ~scored: u64 = 0;
        ~i: u64 = 0;
        W i < 10000 {
            # Simulate scoring a document for a query term
            ~tf = (i % 10 + 1) as u32;        # term frequency 1-10
            ~df = (i % 1000 + 1) as u64;       # document frequency
            ~doc_len = (i % 500 + 50) as u32;  # document length 50-549
            ~avg_len: f64 = 300.0;             # average doc length
            ~total_docs: u64 = 100000;         # corpus size

            scorer.score(tf, df, doc_len, avg_len, total_docs);
            scored += 1;
            i += 1;
        }
        scored
    })
}

# ============================================================================
# FullText: Boolean/Phrase Query Benchmarks
# ============================================================================

# Benchmark: Boolean query parsing
F bench_boolean_parse(harness: &~BenchmarkHarness) -> BenchmarkResult {
    ~config = BenchmarkConfig.default(Str.from("ft_boolean_parse"));
    config = config.with_iterations(100);

    ~queries: Vec<Str> = Vec.new();
    queries.push(Str.from("database AND vector"));
    queries.push(Str.from("search OR query"));
    queries.push(Str.from("insert AND NOT delete"));
    queries.push(Str.from("\"full text search\""));
    queries.push(Str.from("graph AND (traversal OR path)"));
    queries.push(Str.from("vector AND database AND NOT slow"));
    queries.push(Str.from("\"hybrid search\" AND performance"));
    queries.push(Str.from("btree OR hnsw OR inverted"));

    harness.run_simple(&config, || -> u64 {
        ~parsed: u64 = 0;
        ~i: u64 = 0;
        W i < queries.len() {
            M BooleanQueryParser.parse(&queries[i]) {
                Ok(_) => { parsed += 1; },
                Err(_) => {},
            }
            i += 1;
        }
        parsed
    })
}

# Benchmark: Phrase search position matching
F bench_phrase_search(harness: &~BenchmarkHarness) -> BenchmarkResult {
    ~config = BenchmarkConfig.default(Str.from("ft_phrase_search"));
    config = config.with_iterations(50);

    # Build simulated posting entries with positions
    ~term_postings: Vec<Vec<PostingEntry>> = Vec.new();

    # Term 1: "full" — appears in docs 1,3,5,7,9,...
    ~postings1: Vec<PostingEntry> = Vec.new();
    ~i: u64 = 0;
    W i < 500 {
        ~positions: Vec<u32> = Vec.new();
        positions.push((i % 20) as u32);
        positions.push((i % 20 + 10) as u32);
        ~entry = PostingEntry.new(i * 2 + 1, 2, positions, i + 1, 0);
        postings1.push(entry);
        i += 1;
    }
    term_postings.push(postings1);

    # Term 2: "text" — appears in docs 1,2,3,...
    ~postings2: Vec<PostingEntry> = Vec.new();
    i = 0;
    W i < 1000 {
        ~positions: Vec<u32> = Vec.new();
        positions.push((i % 20 + 1) as u32);
        ~entry = PostingEntry.new(i + 1, 1, positions, i + 1, 0);
        postings2.push(entry);
        i += 1;
    }
    term_postings.push(postings2);

    ~terms: Vec<Str> = Vec.new();
    terms.push(Str.from("full"));
    terms.push(Str.from("text"));

    harness.run_simple(&config, || -> u64 {
        ~searcher = PhraseSearcher.new(0);
        # Note: phrase search requires snapshot/clog for MVCC filtering;
        # in benchmarks we simulate by passing dummy snapshot/clog
        # In practice this calls searcher.search_phrase which does position matching
        ~matched: u64 = 0;

        # Manual position-based phrase matching simulation
        ~pi: u64 = 0;
        W pi < term_postings[0].len() {
            ~doc_id = term_postings[0][pi].doc_id;
            # Find same doc in second term's postings
            ~found_in_t2 = false;
            ~qi: u64 = 0;
            W qi < term_postings[1].len() && !found_in_t2 {
                I term_postings[1][qi].doc_id == doc_id {
                    # Check position adjacency
                    ~p1 = term_postings[0][pi].positions[0];
                    ~p2 = term_postings[1][qi].positions[0];
                    I p2 == p1 + 1 {
                        matched += 1;
                    }
                    found_in_t2 = true;
                }
                qi += 1;
            }
            pi += 1;
        }
        matched
    })
}

# ============================================================================
# FullText: Compression Benchmarks
# ============================================================================

# Benchmark: VByte encoding throughput
F bench_vbyte_encode(harness: &~BenchmarkHarness) -> BenchmarkResult {
    ~config = BenchmarkConfig.default(Str.from("ft_vbyte_encode"));
    config = config.with_iterations(100);

    harness.run_simple(&config, || -> u64 {
        ~encoded: u64 = 0;
        ~i: u64 = 0;
        W i < 10000 {
            ~buf: Vec<u8> = Vec.new();
            vbyte_encode(i * 7 + 13, &~buf);
            encoded += 1;
            i += 1;
        }
        encoded
    })
}

# Benchmark: Delta encoding for doc_id lists
F bench_delta_encode(harness: &~BenchmarkHarness) -> BenchmarkResult {
    ~config = BenchmarkConfig.default(Str.from("ft_delta_encode"));
    config = config.with_iterations(100);

    # Generate sorted doc IDs
    ~doc_ids: Vec<u64> = Vec.new();
    ~i: u64 = 0;
    W i < 1000 {
        doc_ids.push(i * 3 + 1);
        i += 1;
    }

    harness.run_simple(&config, || -> u64 {
        ~encoded = delta_encode_doc_ids(&doc_ids);
        ~decoded = delta_decode_doc_ids(&encoded);
        doc_ids.len()
    })
}

# ============================================================================
# Suite Runner
# ============================================================================

# Run all vector, graph, and full-text engine benchmarks
F run_engine_benchmarks() -> BenchmarkHarness {
    ~harness = BenchmarkHarness.new(Str.from("Vector, Graph & FullText Engines"));
    harness.start();

    # Vector: Distance computation
    bench_distance_cosine_128(&~harness);
    bench_distance_cosine_256(&~harness);
    bench_distance_cosine_1536(&~harness);
    bench_distance_l2_128(&~harness);
    bench_distance_dot_128(&~harness);

    # Vector: HNSW insert
    bench_hnsw_insert_128d(&~harness);
    bench_hnsw_insert_1536d(&~harness);

    # Vector: HNSW search
    bench_hnsw_search_recall(&~harness);

    # Vector: Quantization
    bench_sq_encode(&~harness);
    bench_sq_distance(&~harness);

    # Graph: Node/Edge creation
    bench_graph_node_create(&~harness);
    bench_graph_edge_create(&~harness);

    # Graph: Traversal
    bench_graph_bfs(&~harness);
    bench_graph_dfs(&~harness);

    # Graph: Shortest path
    bench_graph_shortest_path(&~harness);

    # FullText: Tokenization
    bench_tokenize_throughput(&~harness);
    bench_tokenize_with_freqs(&~harness);

    # FullText: BM25
    bench_bm25_scoring(&~harness);

    # FullText: Boolean/Phrase
    bench_boolean_parse(&~harness);
    bench_phrase_search(&~harness);

    # FullText: Compression
    bench_vbyte_encode(&~harness);
    bench_delta_encode(&~harness);

    harness.print_report();
    harness
}
